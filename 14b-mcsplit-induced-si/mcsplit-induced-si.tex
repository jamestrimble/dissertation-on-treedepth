%\algnewcommand{\IfNDebug}[1]{#1}
%\algnewcommand{\IfNDebug}[1]{}

\newcommand{\varStartG}{\ensuremath{\AlgVar{start}_G}}
\newcommand{\varEndG}{\ensuremath{\AlgVar{end}_G}}
\newcommand{\varStartH}{\ensuremath{\AlgVar{start}_H}}
\newcommand{\varEndH}{\ensuremath{\AlgVar{end}_H}}
\newcommand{\varActive}{\ensuremath{\AlgVar{active}}}
\newcommand{\varSplitting}{\ensuremath{\AlgVar{splitting}}}
\newcommand{\varPrev}{\ensuremath{\AlgVar{prev}}}
\newcommand{\varNext}{\ensuremath{\AlgVar{next}}}
\newcommand{\labelClass}{\ensuremath{\AlgVar{labelClass}}}
\newcommand{\vertexPtr}{\ensuremath{\AlgVar{vertexPtr}}}
\newcommand{\calLC}{\ensuremath{\mathcal{LC}}}
\newcommand{\LC}{\ensuremath{\AlgVar{LC}}}
\newcommand{\Gptrs}{\ensuremath{\AlgVar{Gptrs}}}
\newcommand{\Hptrs}{\ensuremath{\AlgVar{Hptrs}}}
\newcommand{\Garray}{\ensuremath{A_G}}
\newcommand{\Harray}{\ensuremath{A_H}}

\chapter{McSplit-SI: An algorithm for the induced subgraph isomorphism problem}
\label{c:mcsplit-si}

%% tmp %% \section{Introduction}
%% tmp %% 
%% tmp %% In the induced subgraph isomorphism problem, we seek an induced copy of pattern graph $G$ in target graph $H$. This is a special case of the decision version of maximum common induced subgraph in which we require the common subgraph to contain all of graph $G$'s vertices.
%% tmp %% 
%% tmp %% The \McSplit\ algorithm may be trivially modified to solve the induced subgraph isomorphism problem. Rather than calculating an upper bound at each search node, we simply backtrack when the $G$-set of any label class is larger than the corresponding $H$-set, since by the pigeonhole principle this implies that we cannot map each pattern-graph vertex to a target-graph vertex.
%% tmp %% 
%% tmp %% While \McSplit\ is well suited to the small (tens of vertices), relatively dense pattern and target graphs that are typical of maximum common subgraph instances, it has two disadvantages for large (hundreds or thousands of vertices), sparse graphs that appear in benchmark instances for subgraph isomorphism.  The first disadvantage relates to space: $b(n_G^2 + n_H^2)$ space is needed to store the adjacency matrices, where $b$ is the memory size of a boolean variable.\footnote{We could switch to a more space-efficient representation such as hash-sets of neighbours which would still permit amortized constant time adjacency tests in the algorithm's partitioning step, but this would slow down the algorithm significantly.}  The second disadvantage relates to time: during the partitioning step, the \McSplit\ algorithm iterates over all of the vertices in each label class, which often requires checking close to $n_G + n_H$ adjacency-matrix elements each time the partitioning procedure is carried out.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \includegraphics*[width=0.6\textwidth]{14b-mcsplit-induced-si/density-chart/plots/n-density-pdf}
%% tmp %%     \caption{Number of vertices and density (log scale) for each target graph in the benchmark set
%% tmp %%     of $14,621$ subgraph isomorphism decision instances.}
%% tmp %%     \label{figure:si-targets-n-density}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \Cref{figure:si-targets-n-density} shows vertex count and density for the target graphs of the benchmark instances
%% tmp %% that we will use in this chapter.  Of the entire benchmark set, $76\%$ of pattern graphs have density less than $0.01$.  Thus, it would
%% tmp %% greatly improve our \McSplit\ algorithm for subgraph isomorphism on these and similar instances if we could reduce the time complexity of the partitioning
%% tmp %% step from $O(n_G + n_H)$ to $O(|N(v)| + |N(w)|)$, where $(v,w)$ is the most-recently made mapping of a pattern vertex to a target
%% tmp %% vertex.  In this chapter we introduce this improved algorithm, which we call \McSplit-SI.
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \section{The label class object}
%% tmp %% 
%% tmp %% In the basic version of the \McSplit\ algorithm that was described in
%% tmp %% \Cref{c:mcsplit-i-undirected}, the label class objects at each level of the search tree are stored
%% tmp %% contiguously in an array, and each object representing
%% tmp %% a label class $\langle S_G, S_H \rangle$ requires only four indices or pointers: to the start and
%% tmp %% end of the array slices that contain $S_G$ and $S_H$.
%% tmp %% To enable partitioning in $O(|N_G(v)| + |N_H(w)|)$ time, \McSplit-SI
%% tmp %% requires a more elaborate label-class object, and stores the objects in a doubly-linked list which is modified
%% tmp %% when partitioning domains and restored on backtracking.
%% tmp %% 
%% tmp %% \Cref{tab:mcsplit-si-object} lists the member variables of a label class object.
%% tmp %% The first two members are $\AlgVar{prev}$ and $\AlgVar{next}$ pointers, which
%% tmp %% allow the set of label classes to be jointed together as a doubly-linked list.
%% tmp %% These pointers are useful not only for iterating over the list but also
%% tmp %% for restoring deleted elements when backtracking, as we will discuss later in the chapter.
%% tmp %% 
%% tmp %% The next four members of the object play the same role as the four indices used in \McSplit's
%% tmp %% simpler label class object: they point to the ranges in the permuations of $V(G)$ and $V(H)$ that
%% tmp %% contain $S_G$ and $S_H$.
%% tmp %% 
%% tmp %% Finally, we have two boolean flags, $\varActive$ and $\varSplitting$.  The first flag
%% tmp %% records whether the label class object is currently in the list of label classes.  (Inactive
%% tmp %% label classes have been deleted, but are maintained in memory so that they can be restored
%% tmp %% when backtracking.)  The second flag is used temporarily during the partitioning step
%% tmp %% to record which label class have been partitioned.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%  \begin{tabular}{p{0.13\linewidth} p{0.2\linewidth} p{0.5\linewidth}}
%% tmp %%  \toprule
%% tmp %%     Name & Type & Description \\ [0.5ex]
%% tmp %%  \midrule
%% tmp %%     $\AlgVar{prev}$ & Pointer to Label Class & The previous label class in the doubly-linked list of all label classes \\
%% tmp %%     \rule{0pt}{2.3ex}$\AlgVar{next}$ & Pointer to Label Class & The next label class in the doubly-linked list of all label classes \\
%% tmp %%     \rule{0pt}{2.3ex}\varStartG & Pointer to Integer & Pointer to the first vertex of the $G$-set\\
%% tmp %%     \rule{0pt}{2.3ex}\varEndG & Pointer to Integer & Pointer to one element past the last vertex of the $G$-set\\
%% tmp %%     \rule{0pt}{2.3ex}\varStartH & Pointer to Integer & Pointer to the first vertex of the $H$-set\\
%% tmp %%     \rule{0pt}{2.3ex}\varEndH & Pointer to Integer & Pointer to one element past the last vertex of the $H$-set\\
%% tmp %%     \rule{0pt}{2.3ex}$\AlgVar{active}$ & Boolean & Is this label class in the doubly linked list? \\
%% tmp %%     \rule{0pt}{2.3ex}$\AlgVar{splitting}$ & Boolean & Is this label class being split? \\
%% tmp %%  \bottomrule
%% tmp %% \end{tabular}
%% tmp %% \caption{The member variables of \McSplit-SI label class object}
%% tmp %% \label{tab:mcsplit-si-object}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% The collection of data structures used by \McSplit-SI to represent the set of active label
%% tmp %% classes has three components.  The first of these is the the doubly-linked list of label
%% tmp %% class objects that we have described; we refer to this as \calLC.  The second 
%% tmp %% component is the pair of arrays that store partitions of $V(G)$ and $V(H)$ that are pointed
%% tmp %% to by each label class object.   We call these arrays $\Garray$ and $\Harray$.
%% tmp %% 
%% tmp %% The final component of our collection of data structures contains two arrays, $\Gptrs$
%% tmp %% and $\Hptrs$.  These contain
%% tmp %% an object for each vertex $v$ of $G$ and $H$ respectively.  Each object contains two pointers.
%% tmp %% The first pointer of $\Gptrs[v]$ points to the position in $\Garray$ at which $v$
%% tmp %% appears, and the second points to the label class containing $v$.
%% tmp %% Similarly, the pointers of $\Hptrs[w]$ point to the position in $\Harray$ at which $w$
%% tmp %% appears and the label class containing $w$.
%% tmp %% The arrays $\AlgVar{Gptrs}$ and $\AlgVar{Hptrs}$ allows us to perform constant-time
%% tmp %% manipulations to label classes given only a vertex; it is these arrays that enable
%% tmp %% \McSplit-SI to carry out the partitioning step without iterating over the vertices in each label class.
%% tmp %% 
%% tmp %% TODO move this sentence:
%% tmp %% Initially, the doubly-linked list of label classes contains a single element representing
%% tmp %% all vertices of graphs $G$ and $H$.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \scalebox{.8}{
%% tmp %%         \tikz {
%% tmp %%             \graph [nodes={draw, circle, minimum width=.55cm, inner sep=1pt}, circular placement, radius=0.95cm,
%% tmp %%                     clockwise=5] {
%% tmp %%                         1,2,3,4,5;
%% tmp %%                 1--4; 1--5; 2--3; 2--5; 3--5;
%% tmp %%             };
%% tmp %%         }
%% tmp %%         \qquad\qquad
%% tmp %%         \tikz {
%% tmp %%             \graph [nodes={draw, circle, minimum width=.55cm, inner sep=1pt}, circular placement, radius=0.95cm,
%% tmp %%                     clockwise=6, phase=60] {
%% tmp %%                         a,b,c,d,e,f;
%% tmp %%                 a--b; a--c; a--e; b--d; b--f; c--d; c--e; c--f; d--f; e--f;
%% tmp %%             };
%% tmp %%         }
%% tmp %%     }
%% tmp %%     \caption{Example graphs $G$ and $H$}
%% tmp %%     \label{figure:example-g-and-h-redux}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \Cref{figure:example-g-and-h-redux} reproduces, for convenience, the example
%% tmp %% graphs from \Cref{c:mcsplit-i-undirected} which we will also use for our running example
%% tmp %% in this chapter.
%% tmp %% \Cref{figure:si-data-structures} shows the data structures of \McSplit-SI
%% tmp %% after making the assignment $(1,a)$ in the induced subgraph isomorphism instance with pattern
%% tmp %% graph $G$ and target graph $H$.  In the middle row of the figure we have the doubly-linked
%% tmp %% list $\calLC$.  Immediately above and below this are the $\Garray$ and $\Harray$ arrays.
%% tmp %% At the top and bottom are the arrays $\Gptrs$ and $\Hptrs$.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \includegraphics*[width=0.9\textwidth]{14b-mcsplit-induced-si/figs/data-structure-step-1}
%% tmp %%     \caption{The data structures of \McSplit-SI after assigning vertex $1$ to vertex $a$.
%% tmp %%         Circles represent pointers; hollow circles are null pointers.  The middle row shows
%% tmp %%         the doubly-linked list of label classes.  Shown immediately above and below this are the
%% tmp %%         permutations of $V(G)$ and $V(H)$, stored as arrays.  The top and bottom rows
%% tmp %%         show the arrays $\AlgVar{Gptrs}$ and $\AlgVar{Hptrs}$.  Each element of these arrays
%% tmp %%         corresponds to a vertex $v$ of $G$ or $H$, and points to the position of $v$
%% tmp %%         the permutation and to the label class containing $v$.  To reduce clutter in the diagram,
%% tmp %%         the label class pointers are shown pointing to a rectangle of the same colour as the
%% tmp %%         label class.}
%% tmp %%     \label{figure:si-data-structures}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \section{The algorithm}
%% tmp %% 
%% tmp %% \Cref{McSplitSIAlg} presents the overall structure of \McSplit-SI.  The entry point is
%% tmp %% on \lineref{McSplitSIFun}.  If $G$ has more vertices than $H$, the instance is trivially
%% tmp %% unsatisfiable. Otherwise, the global data label-class data structures are set up with
%% tmp %% a single label class, and the main recursive function $\FuncSty{Search}$ is called with
%% tmp %% an empty mapping.
%% tmp %% 
%% tmp %% \Lineref{McSplitSIReturnTrue} returns true if a mapping containing all vertices of the
%% tmp %% pattern graph has been found.  Otherwise, the algorithm selects a label class
%% tmp %% $\langle S_G, S_H \rangle$, and from within $S_G$ a vertex on which to branch.
%% tmp %% (We will discuss variable selection heuristics in section ...) We then iterate
%% tmp %% over the vertices $w$ in $S_H$, attemptying to map $v$ to $w$.
%% tmp %% 
%% tmp %% \begin{algorithm}[htb]
%% tmp %% \AlgorithmFontSize
%% tmp %% \DontPrintSemicolon
%% tmp %% \nl $\FuncSty{Search}(M)$ \;
%% tmp %% \nl \Begin{
%% tmp %%     \nl \lIf {$|M| = |V(G)|$}{\KwSty{return} $\AlgVar{true}$} \label{McSplitSIReturnTrue}
%% tmp %% \medskip
%% tmp %% \nl $\langle \setG,\setH \rangle \gets \FuncSty{SelectLabelClass}()$ \label{McSplitSISelectClass} \;
%% tmp %% \nl $v \gets \FuncSty{SelectVertex}(\setG)$ \label{McSplitSISelectVertex} \;
%% tmp %%     \nl \For {$w \in \setH$ \label{McSplitSIWLoop}} {
%% tmp %%     \nl    $\FuncSty{Assign}(v,w)$ \LeftComment{\Cref{McSplitSIAlgAssign}} \;
%% tmp %% \nl    $(\AlgVar{splits}, \AlgVar{deletions}, \AlgVar{failed}) \gets \FuncSty{Filter}(v, w)$ 
%% tmp %%                 \LeftComment{\Cref{McSplitSIAlgFilter}} \;
%% tmp %% \nl    \If{
%% tmp %% \nl         $\AlgVar{failed}$}{ $\AlgVar{success} \gets \AlgVar{false}$
%% tmp %% }
%% tmp %% \nl    \Else {
%% tmp %% \nl         $\AlgVar{success} \gets \FuncSty{Search}(M \cup \{(v,w)\})$
%% tmp %% }
%% tmp %% \nl    $\FuncSty{Unfilter}(\AlgVar{splits}, \AlgVar{deletions})$ 
%% tmp %%                 \LeftComment{\Cref{McSplitSIAlgUnfilter}} \;
%% tmp %% \nl    $\FuncSty{Unassign}(v,w,\langle \setG,\setH \rangle)$ \LeftComment{\Cref{McSplitSIAlgAssign}} \;
%% tmp %% \nl    \lIf {$\AlgVar{success}$}{$\KwSty{return}$ $\AlgVar{true}$}
%% tmp %%   }
%% tmp %% \nl  $\KwSty{return}$ $\AlgVar{false}$\;
%% tmp %% }
%% tmp %% \;
%% tmp %% \nl $\FuncSty{McSplitSI}(\graphG,\graphH)$ \label{McSplitSIFun} \;
%% tmp %% \nl \Begin{
%% tmp %% \nl \lIf {$|V(G)| > |V(H)|$}{\KwSty{return} $\AlgVar{false}$}
%% tmp %% \nl Initialise global data structure with the label class $\{\langle V(\graphG),V(\graphH) \rangle \}$ \;
%% tmp %% \nl $\KwSty{return}$ $\FuncSty{Search}(\emptyset)$ \label{McSplitSIFirstExpandCall} \;
%% tmp %% }
%% tmp %% \caption{\McSplit-SI}
%% tmp %% \label{McSplitSIAlg}
%% tmp %% \end{algorithm}
%% tmp %% 
%% tmp %% Within this loop, we have two pairs of functions:
%% tmp %% $\FuncSty{Assign}$ / $\FuncSty{Unassign}$
%% tmp %% and
%% tmp %% $\FuncSty{Filter}$ / $\FuncSty{Unfilter}$.  In each pair, the
%% tmp %% second function reverses the action of the first on the global
%% tmp %% data structure of label classes.
%% tmp %% 
%% tmp %% The first pair of functions is shown in \Cref{McSplitSIAlgAssign}.
%% tmp %% Both of these run in constant time.
%% tmp %% The function $\FuncSty{Assign}(v,w)$ updates the label classes to reflect
%% tmp %% the assignment of $v$ in the pattern graph to $w$ in the target graph.  It 
%% tmp %% does this by moving $v$ and $w$ to the end of their label class in
%% tmp %% $\Garray$ and $\Harray$, then decrementing the end pointers of the label class.
%% tmp %% If no vertices of the pattern graph remain in the label class, the label-class
%% tmp %% object is deleted from the linked list $\calLC$.
%% tmp %% 
%% tmp %% In addition, to maintain the invariants of
%% tmp %% the $\AlgVar{Gptrs}$ and $\AlgVar{Hptrs}$ arrays, we set the label-class pointers of
%% tmp %% $\AlgVar{Gptrs}[v]$ and $\AlgVar{Hptrs}[w]$ to null since these vertices
%% tmp %% are no longer in a label class, and update the vertex pointers
%% tmp %% for $v$, $w$, and the vertices with which these were swapped to point to these
%% tmp %% vertices' new positions in the $V_G$ and $V_H$ arrays.
%% tmp %% \Cref{figure:si-data-structures-2} shows the data structures after the assignment
%% tmp %% of $2$ to $d$ in our example.
%% tmp %% 
%% tmp %% \begin{algorithm}[htb]
%% tmp %% \AlgorithmFontSize
%% tmp %% \DontPrintSemicolon
%% tmp %% \nl $\FuncSty{Assign}(v,w)$ \;
%% tmp %% \nl \Begin{
%% tmp %% \nl   $\LC \gets \Gptrs[v].\labelClass$ \;
%% tmp %% \medskip
%% tmp %% \nl   \LeftComment{delete $v$ from \LC} \;
%% tmp %% \nl   $u \gets$ the vertex in $\Garray$ whose address is one element before $\LC.\AlgVar{end}_G$ \;
%% tmp %% \nl   Swap $v$ with $u$ in $\Garray$, using the address of $v$ in $\Gptrs[v].\vertexPtr$ \;
%% tmp %% \nl   Swap $\Gptrs[v].\vertexPtr$ with $\Gptrs[u].\vertexPtr$ \;
%% tmp %% \nl   Decrement $\LC.\AlgVar{end}_G$ \;
%% tmp %% \nl   $\Gptrs[v].\labelClass \gets \AlgVar{null}$ \;
%% tmp %% \medskip
%% tmp %% \nl   \LeftComment{delete $w$ from \LC} \;
%% tmp %% \nl   $u \gets$ the vertex in $\Harray$ whose address is one element before $\LC.\AlgVar{end}_H$ \;
%% tmp %% \nl   Swap $w$ with $u$ in $\Harray$, using the address of $w$ in $\Hptrs[w].\vertexPtr$ \;
%% tmp %% \nl   Swap $\Hptrs[w].\vertexPtr$ with $\Hptrs[u].\vertexPtr$ \;
%% tmp %% \nl   Decrement $\LC.\AlgVar{end}_H$ \;
%% tmp %% \nl   $\Hptrs[w].\labelClass \gets \AlgVar{null}$ \;
%% tmp %% \medskip
%% tmp %% \nl   \If{$\LC.\varStartG = \LC.\varEndG$}{
%% tmp %% \nl     \LeftComment{Delete $\LC$ from the doubly linked list of label classes} \;
%% tmp %% \nl     $\LC.\varPrev.\varNext \gets \LC.\varNext$ \;
%% tmp %% \nl     $\LC.\varNext.\varPrev \gets \LC.\varPrev$ \;
%% tmp %%       }
%% tmp %% }
%% tmp %% \;
%% tmp %% \nl $\FuncSty{Unassign}(v,w,\LC)$ \;
%% tmp %% \nl \Begin{
%% tmp %% \nl   \If{$\LC.\varStartG = \LC.\varEndG$}{
%% tmp %% \nl     \LeftComment{Restore $\LC$ to the doubly linked list of label classes} \;
%% tmp %% \nl     $\LC.\varPrev.\varNext \gets \LC$ \;
%% tmp %% \nl     $\LC.\varNext.\varPrev \gets \LC$ \;
%% tmp %%       }
%% tmp %% \medskip
%% tmp %% \nl   \LeftComment{restore $v$ and $w$ to \LC} \;
%% tmp %% \nl   $\Gptrs[v].\labelClass \gets \LC$ \;
%% tmp %% \nl   $\Hptrs[w].\labelClass \gets \LC$ \;
%% tmp %% \nl   Increment $\LC.\AlgVar{end}_G$ \;
%% tmp %% \nl   Increment $\LC.\AlgVar{end}_H$ \;
%% tmp %% }
%% tmp %% \caption{The $\FuncSty{Assign}$ and $\FuncSty{Unassign}$ functions of \McSplit-SI}
%% tmp %% \label{McSplitSIAlgAssign}
%% tmp %% \end{algorithm}
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \includegraphics*[width=0.9\textwidth]{14b-mcsplit-induced-si/figs/data-structure-step-2}
%% tmp %%     \caption{The data structures after mapping vertex $2$ to vertex $d$.}
%% tmp %%     \label{figure:si-data-structures-2}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \section{The partitioning algorithm}
%% tmp %% 
%% tmp %% We now describe the partitioning step, referring in our running example to
%% tmp %% the refinement of label classes carried out after mapping $2$ to $d$.
%% tmp %% \Cref{figure:si-data-structures-3} shows the data structures after this step is completed.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \includegraphics*[width=0.9\textwidth]{14b-mcsplit-induced-si/figs/data-structure-step-3}
%% tmp %%     \caption{The data structures after partitioning}
%% tmp %%     \label{figure:si-data-structures-3}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% Each label class object that contained the sets $\langle V_G, V_H \rangle$ prior
%% tmp %% to the partitioning process contains $\langle V_G \setminus N_G(v), V_H \setminus N_H(w)\rangle$
%% tmp %% at the end of the partitioning process.  If either $V_G \cap H_G(v)$ or $V_H \cap N_H(w)$
%% tmp %% is non-empty, the partitioning process creates a new label class object
%% tmp %% $\langle V_G \cap N_G(v), V_H \cap N_H(w)\rangle$ which is
%% tmp %% positioned in the doubly linked list immediately after the original label class.
%% tmp %% To carry out the process, we iterate over $N_G(v)$ then $N_H(w)$,
%% tmp %% creating new label classes as required, as shown in the function $\FuncSty{Filter}$
%% tmp %% in \Cref{McSplitSIAlgFilter}.
%% tmp %% 
%% tmp %% \begin{algorithm}[htb]
%% tmp %% \AlgorithmFontSize
%% tmp %% \DontPrintSemicolon
%% tmp %% \nl $\FuncSty{Filter}(v,w)$ \;
%% tmp %% \nl \Begin{
%% tmp %% \nl  $\AlgVar{splits} \gets []$  \LeftComment{Initialise array of pointers to split label classes} \;
%% tmp %% \medskip 
%% tmp %% \nl  \LeftComment{For each neighbour of $v$ that is in a label class, move $v$ into a new label class} \;
%% tmp %% \nl  \For {$u \in \N_G(v)$\label{FilterGLoop}} {
%% tmp %% \nl      $\LC \gets \Gptrs[u].\labelClass$ \;
%% tmp %% \nl      \If{$\LC = \AlgVar{null}$}{
%% tmp %% \nl          \KwSty{continue} \LeftComment{$u$ is already in $M$, and therefore not in any label class} \;
%% tmp %%          }
%% tmp %% \nl      \If{$\LC.\varSplitting = \AlgVar{false}$}{
%% tmp %% \nl          $\LC.\varSplitting \gets \AlgVar{true}$ \;
%% tmp %% \nl          $\FuncSty{CreateLabelClassAfter}(\LC)$ \LeftComment{\Cref{McSplitSIAlgCreateLC}} \;
%% tmp %% \nl          Append to $\AlgVar{splits}$ a pointer to \LC \;
%% tmp %%          }
%% tmp %% \nl      Swap $u$ to the end of $\LC$ in \Garray, updating the two relevant $\vertexPtr$ members in \Gptrs \;
%% tmp %% \nl      $\Gptrs[u].\labelClass \gets \LC.\varNext$ \;
%% tmp %% \nl      Decrement $\LC.\varEndG$ and $\LC.\varNext.\varStartG$ \LeftComment{Move $u$ from $\LC$ to $\LC.\varNext$} \;
%% tmp %%     }
%% tmp %% \medskip 
%% tmp %% \nl  \LeftComment{For each neighbour of $w$ that is in a label class, move $w$ into a new label class} \;
%% tmp %% \nl  \For {$u \in \N_H(w)$\label{FilterHLoop}} {
%% tmp %% \nl      $\LC \gets \Hptrs[u].\labelClass$ \;
%% tmp %% \nl      \If{$\LC = \AlgVar{null}$}{
%% tmp %% \nl          \KwSty{continue} \LeftComment{$u$ is already in $M$, and therefore not in any label class} \;
%% tmp %%          }
%% tmp %% \nl      \If{$\LC.\varActive = \AlgVar{false}$}{
%% tmp %% \nl          \LeftComment{The label class containing $u$ was deleted at a shallower level of the search tree} \;
%% tmp %% \nl          \KwSty{continue} \;
%% tmp %%          }
%% tmp %% \nl      \If{$\LC.\varSplitting = \AlgVar{false}$}{
%% tmp %% \nl          $\LC.\varSplitting \gets \AlgVar{true}$ \;
%% tmp %% \nl          $\FuncSty{CreateLabelClassAfter}(\LC)$ \LeftComment{\Cref{McSplitSIAlgCreateLC}}\;
%% tmp %% \nl          Append to $\AlgVar{splits}$ a pointer to \LC \;
%% tmp %%          }
%% tmp %% \nl      Swap $u$ to the end of $\LC$ in \Harray, updating the two relevant $\vertexPtr$ members in \Hptrs \;
%% tmp %% \nl      $\Hptrs[u].\labelClass \gets \LC.\varNext$ \;
%% tmp %% \nl      Decrement $\LC.\varEndH$ and $\LC.\varNext.\varStartH$ \LeftComment{Move $u$ from $\LC$ to $\LC.\varNext$} \;
%% tmp %%     }
%% tmp %% \medskip
%% tmp %% \nl  \For {$\LC \in \AlgVar{splits}$} {
%% tmp %% \nl     $\LC.\varSplitting \gets \AlgVar{false}$ \;
%% tmp %% }
%% tmp %% \medskip
%% tmp %% \nl  \For {$\LC \in \AlgVar{splits}$ \label{McSplitSIBacktrackEarlyLoop}} {
%% tmp %% \nl     \If{$\LC.\varEndG - \LC.\varStartG > \LC.\varEndH - \LC.\varStartH$}{
%% tmp %% \nl         $\KwSty{return}$ $(\AlgVar{splits},[],\AlgVar{true})$
%% tmp %% }
%% tmp %% \nl     \If{$\LC.next.\varEndG - \LC.next.\varStartG > \LC.next.\varEndH - \LC.next.\varStartH$}{
%% tmp %% \nl         $\KwSty{return}$ $(\AlgVar{splits},[],\AlgVar{true})$
%% tmp %% }
%% tmp %% }
%% tmp %% \medskip
%% tmp %%     \nl  $\AlgVar{deletions} \gets \FuncSty{DoDeletions}(\AlgVar{splits})$
%% tmp %%                 \LeftComment{\Cref{McSplitSIAlgDelete}} \label{McSplitSIDoDeletions}\;
%% tmp %% \medskip
%% tmp %% \nl  $\KwSty{return}$ $(\AlgVar{splits}, \AlgVar{deletions}, \AlgVar{false})$ \label{ReturnFromFilter}\;
%% tmp %% }
%% tmp %% \caption{The $\FuncSty{Filter}$ function}
%% tmp %% \label{McSplitSIAlgFilter}
%% tmp %% \end{algorithm}
%% tmp %% 
%% tmp %% \begin{algorithm}[htb]
%% tmp %% \AlgorithmFontSize
%% tmp %% \DontPrintSemicolon
%% tmp %% \nl $\FuncSty{CreateLabelClassAfter}(\LC)$ \;
%% tmp %% \nl \Begin{
%% tmp %% \nl    Insert a new label class object $\LC'$ after $\LC$ in the doubly linked list \;
%% tmp %% \nl    $\LC'.\varStartG \gets \LC.\varEndG$ \;
%% tmp %% \nl    $\LC'.\varEndG \gets \LC.\varEndG$ \;
%% tmp %% \nl    $\LC'.\varStartH \gets \LC.\varEndH$ \;
%% tmp %% \nl    $\LC'.\varEndH \gets \LC.\varEndH$ \;
%% tmp %% \nl    $\LC'.\varActive \gets \AlgVar{true}$ \;
%% tmp %% \nl    $\LC'.\varSplitting \gets \AlgVar{false}$ \;
%% tmp %% }
%% tmp %% \caption{The $\FuncSty{CreateLabelClassAfter}$ function}
%% tmp %% \label{McSplitSIAlgCreateLC}
%% tmp %% \end{algorithm}
%% tmp %% 
%% tmp %% \section{Cleanup}
%% tmp %% 
%% tmp %% In \Cref{figure:si-data-structures-3}, we can see that the first label class
%% tmp %% now contains no elements of $V_G$.  As a result, we can safely delete this label
%% tmp %% class object from the linked list.  The general procedure of deletion is as
%% tmp %% follows.\footnote{Our implementation has an extra pointer within each label
%% tmp %% class object so we can store the deleted\_label\_classes list as a linked list
%% tmp %% without the need for an external array of pointers.}
%% tmp %% 
%% tmp %% 
%% tmp %% \begin{algorithm}[htb]
%% tmp %% \AlgorithmFontSize
%% tmp %% \DontPrintSemicolon
%% tmp %% \nl $\FuncSty{DoDeletions}(\AlgVar{splits})$ \;
%% tmp %% \nl \Begin{
%% tmp %% \nl   $\AlgVar{deletions} \gets []$  \LeftComment{Initialise list of pointers to deleted label classes} \;
%% tmp %% \medskip 
%% tmp %% \nl   \For {$\LC \in \AlgVar{splits}$} {
%% tmp %% \nl     \If {$\LC.\varStartG = \LC.\varEndG$} {
%% tmp %% \nl         $\FuncSty{DeleteLabelClass}(\LC)$ \;
%% tmp %% \nl         Append $\LC$ to $\AlgVar{deletions}$
%% tmp %%         } 
%% tmp %% \nl     \If {$\LC.next.\varStartG = \LC.next.\varEndG$} {
%% tmp %% \nl         $\FuncSty{DeleteLabelClass}(\LC.next)$ \;
%% tmp %% \nl         Append $\LC.next$ to $\AlgVar{deletions}$
%% tmp %%         } 
%% tmp %%     }
%% tmp %%     $\KwSty{return}$ $\AlgVar{deletions}$ \;
%% tmp %% }
%% tmp %% \;
%% tmp %% \nl $\FuncSty{DeleteLabelClass}(\LC)$ \;
%% tmp %% \nl \Begin{
%% tmp %% \nl     $\LC.\varPrev.\varNext \gets \LC.\varNext$ \;
%% tmp %% \nl     $\LC.\varNext.\varPrev \gets \LC.\varPrev$ \;
%% tmp %% \nl     $\LC.\varActive \gets \AlgVar{false}$
%% tmp %% }
%% tmp %% \caption{The $\FuncSty{DoDeletions}$ function}
%% tmp %% \label{McSplitSIAlgDelete}
%% tmp %% \end{algorithm}
%% tmp %% 
%% tmp %% We do not garbage-collect this label class, and
%% tmp %% we leave its $\AlgVar{prev}$ and $\AlgVar{next}$ 
%% tmp %% pointers unchanged; we will use these pointers' values to return
%% tmp %% the label class to the doubly linked list when backtracking.
%% tmp %% 
%% tmp %% After calling the $\FuncSty{DoDeletions}$ function,
%% tmp %% the $\FuncSty{Filter}$ function returns on \lineref{ReturnFromFilter} 
%% tmp %% of \Cref{McSplitSIAlgFilter}.  Three values are returned. The lists
%% tmp %% of split label classes and deleted label classes will be used to restore
%% tmp %% the data structure when backtracking. The final returned value is a boolean
%% tmp %% flag that indicates that the filtering step completed successfully
%% tmp %% without finding a reason to backtrack immediately.
%% tmp %% 
%% tmp %% A small implementation detail: rather than storing these returned values
%% tmp %% as linear lists of pointers, we store two additional pointers within
%% tmp %% each label class so that the lists can be stored as (intrusive) singly linked
%% tmp %% lists without any need to allocate additional arrays.  In the case of the
%% tmp %% $\AlgVar{splits}$ list, our implementation returns a list of the newly-created
%% tmp %% label classes rather than their parents.
%% tmp %% 
%% tmp %% \section{Backtracking}
%% tmp %% 
%% tmp %% On backtracking, we must undo in reverse order the three steps of
%% tmp %% mapping a vertex, splitting label classes, and deleting label classes.
%% tmp %% 
%% tmp %% First, we undo deletions, restoring each deleted label classes to its
%% tmp %% original position in the doubly linked list using the ``dancing links'' method
%% tmp %% introduced by (cite) and described by Knuth (cite).
%% tmp %% 
%% tmp %% \begin{algorithm}[htb]
%% tmp %% \AlgorithmFontSize
%% tmp %% \DontPrintSemicolon
%% tmp %% \nl $\FuncSty{Unfilter}(\AlgVar{splits}, \AlgVar{deletions})$ \;
%% tmp %% \nl \Begin{
%% tmp %% \nl   \For {$\LC \in \AlgVar{deletions}$, in reverse order} {
%% tmp %% \nl     \LeftComment{Restore \LC} \;
%% tmp %% \nl     $\LC.\varPrev.\varNext \gets \LC$ \;
%% tmp %% \nl     $\LC.\varNext.\varPrev \gets \LC$ \;
%% tmp %% \nl     $\LC.\varActive \gets \AlgVar{true}$
%% tmp %%     }
%% tmp %% \nl   \For {$\LC \in \AlgVar{splits}$, in reverse order} {
%% tmp %% \nl     \LeftComment{Merge \LC.next into \LC} \;
%% tmp %% \nl     \lFor{$u$ in the set $S_G$ of \LC.next}{$\Gptrs[u].\labelClass \gets \LC$}
%% tmp %% \nl     \lFor{$u$ in the set $S_H$ of \LC.next}{$\Hptrs[u].\labelClass \gets \LC$}
%% tmp %% \nl     $\LC.\varEndG \gets \LC.next.\varEndG$ \;
%% tmp %% \nl     $\LC.\varEndH \gets \LC.next.\varEndH$ \;
%% tmp %% \nl     Remove $\LC.next$ from the doubly linked list of label classes
%% tmp %%     }
%% tmp %% }
%% tmp %% \caption{The $\FuncSty{Unfilter}$ function}
%% tmp %% \label{McSplitSIAlgUnfilter}
%% tmp %% \end{algorithm}
%% tmp %% 
%% tmp %% Next, we undo splits.  Just as in \McSplit, there is
%% tmp %% no need to reorder the $V_G$ and $V_H$ permutations when backtracking.
%% tmp %% 
%% tmp %% Finally, we undo the vertex mapping by calling $\FuncSty{Unassign}$.
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \section{Finding all solutions}
%% tmp %% 
%% tmp %% The \McSplit-SI algorithm that we have described so far determines whether there
%% tmp %% exists an isomorphism from the pattern graph to an induced subgraph of the target
%% tmp %% graph.  We can trivially modify the program to solve the enumeration problem
%% tmp %% of counting \emph{all} such matchings.  The only change that is required is
%% tmp %% to increment a global counter of solutions on
%% tmp %% \lineref{McSplitSIReturnTrue} of \label{McSplitSIAlg} rather than returning
%% tmp %% $\AlgVar{true}$.
%% tmp %% 
%% tmp %% \section{Optimisations}
%% tmp %% 
%% tmp %% This section describes optimisations in our implementation of \McSplit-SI.
%% tmp %% 
%% tmp %% \subsection{Lazy partitioning}\label{subsec:lazy-partitioning}
%% tmp %% 
%% tmp %% The partitioning loops beginning on \lineref{FilterGLoop}
%% tmp %% and \lineref{FilterHLoop} of \Cref{McSplitSIAlgFilter} are critical to
%% tmp %% the performance of the algorithm; the Linux \texttt{perf} utility shows
%% tmp %% that the program typically spends more than half of its execution time
%% tmp %% on these two loops.  Therefore, it is helpful to do as little work in these
%% tmp %% loops as possible.
%% tmp %% 
%% tmp %% To reduce the work carried out in these loops, our implementation does
%% tmp %% not create new label classes or swap vertices during the loops; these
%% tmp %% tasks are delayed until just before \lineref{McSplitSIDoDeletions}.
%% tmp %% Often, the algorithm is able to determine that the subproblem
%% tmp %% is infeasible during the loop beginning on line
%% tmp %% \lineref{McSplitSIBacktrackEarlyLoop}, and therefore does
%% tmp %% not need to create the new label classes or move vertices at all.
%% tmp %% 
%% tmp %% \subsection{Memory allocation}
%% tmp %% 
%% tmp %% Our implementation aims to make as few calls to the system memory allocator as possible when creating
%% tmp %% new label class objects.  We have implemented a very simple allocator, as follows.  There is a \emph{free list}
%% tmp %% of label class objects, which is a singly-linked list of objects that are not currently in use.  When
%% tmp %% a new label class is required, the first element of the free list is used.  If the free list is empty,
%% tmp %% we allocate a contiguous pool of 100 label class objects using the system allocator (in order to improve
%% tmp %% locality of reference), and add each of these to the free list.  A label class is deleted simply by
%% tmp %% adding it to the head of the free list.  The pools of objects are released by the system allocator only when
%% tmp %% the algorithm terminates.
%% tmp %% 
%% tmp %% Using this approach, the partitioning step does not need to make any dynamic memory allocations, except
%% tmp %% on rare occasions when the free list is exhausted.
%% tmp %% This approach to memory allocation typically reduces run time by around $10\%$ in comparison to use of
%% tmp %% C++'s $\FuncSty{new}$ and $\FuncSty{delete}$ keywords for each allocation and deallocation.
%% tmp %% 
%% tmp %% \section{Variants: vertex and edge labels and directed graphs}
%% tmp %% 
%% tmp %% \McSplit-SI can be straightforwardly extended to support vertex labels (and loops, by
%% tmp %% treating a loop as a label modifier) using essentially
%% tmp %% the same method as in \McSplit: for each vertex label $l$ that appears in the pattern graph,
%% tmp %% we initially create a a label class that contains all vertices in the pattern and target
%% tmp %% graphs that have label $l$.  If any of these initial label classes contains more pattern vertices
%% tmp %% than target vertices, the algorithm can report failure immediately without calling
%% tmp %% $\FuncSty{Search}()$.
%% tmp %% 
%% tmp %% Our implementation supports directed graphs using a straightforward approach.  For each
%% tmp %% vertex, we store lists of in-edges and out-edges separately.  The call to $\FuncSty{Filter}()$
%% tmp %% in \Cref{McSplitSIAlg} is then replaced with two calls: the first one for in-edges, the second
%% tmp %% for out-edges.  Correspondingly, two calls are made to $\FuncSty{Unfilter}()$ in reverse
%% tmp %% order of the calls to $\FuncSty{Filter}()$.
%% tmp %% 
%% tmp %% The current implementation of \McSplit-SI does not support edge labels, but it
%% tmp %% would be possible to do so with a fairly simple modification to the algorithm.
%% tmp %% Moreover, this modification does not change the
%% tmp %% $O(|N_G(v)| + |N_H(w)|)$ time complexity of the filtering step.  We assume that
%% tmp %% the labels belong to some ordered set such as the integers.  The key is to sort
%% tmp %% the adjacency lists according to edge label before running the \McSplit-SI
%% tmp %% algorithm: each adjacency list $N(v)$ is sorted such that if the label on edge
%% tmp %% $\{v,u\}$ is less than the label on $\{v,u'\}$ then $u$ appears before $u'$ in
%% tmp %% the adjacency lists.  When partitioning is carried out, the
%% tmp %% vertices in each new label class are therefore ordered by edge label.
%% tmp %% By simultaneously
%% tmp %% traversing the $S_G$ and $S_H$ sets of a new label class from left to right, we
%% tmp %% can subdivide the label class according to edge labels.  This is similar to how
%% tmp %% edge labels are handled in \McSplit; unlike \McSplit, however, the
%% tmp %% data structures of \McSplit-SI allow us to avoid sorting in the $\FuncSty{Filter}()$
%% tmp %% function.
%% tmp %% 
%% tmp %% \section{Variable and value ordering heuristics}
%% tmp %% 
%% tmp %% The speed of \McSplit-SI, like that of other subgraph isomorphism solvers
%% tmp %% \cite{DBLP:journals/tcbb/BonniciG17,DBLP:journals/jair/McCreeshPST18},
%% tmp %% is greatly affected by the order
%% tmp %% in which pattern and target vertices are chosen during search.
%% tmp %% Using terminology from constraint programming, we call the strategy
%% tmp %% used to select a pattern vertex on \lineref{McSplitSISelectVertex} of
%% tmp %% \Cref{McSplitSIAlg} the \emph{variable ordering heuristic}, and the
%% tmp %% strategy used to decide the iteration order over target vertices on
%% tmp %% \lineref{McSplitSIWLoop} the \emph{value ordering heuristic}.
%% tmp %% 
%% tmp %% Our variable ordering heuristic is the \emph{smallest domain first} heuristic,
%% tmp %% which is commonly used in constraint programming and was proposed as early as
%% tmp %% 1965 \cite{golomb1965backtrack}.
%% tmp %% This heuristic is also used by the Glasgow Subgraph Solver.
%% tmp %% In \McSplit-SI, the smallest domain first heuristic requires
%% tmp %% that we choose a vertex $v$ from a label class $\langle G, H \rangle$ with
%% tmp %% as small a set $H$ as possible.  This leaves open the question of how
%% tmp %% to choose among vertices with equally small domains.
%% tmp %% 
%% tmp %% As a first step towards understanding the effect of value ordering heuristics
%% tmp %% and tie-breaking rules for variable ordering heuristics, we carried out an experiment
%% tmp %% with random undirected graphs from the $G(n,p)$ model, in which pattern and target
%% tmp %% densities were varied from $0$ to $1$ in steps of $0.01$ (for a total of $10201$
%% tmp %% pairs of pattern density and target density).  We considered two tie-breaking
%% tmp %% strategies for the variable order heuristic: prefer pattern vertices of low
%% tmp %% degree (``G increasing'') and prefer pattern vertices of high degree (``G decreasing'').
%% tmp %% We considered two corresponding value ordering heuristics based on the degree of target
%% tmp %% vertices: ``H increasing'' and ``H decreasing''.  We ran the experiment three times,
%% tmp %% with 8-, 12- and 16-vertex pattern graphs; in each case, the target graph had 80 vertices.
%% tmp %% Search effort was measured by counting the number of calls to $\FuncSty{Search}$.
%% tmp %% Each run was repeated 32 times, and an average (mean) number of calls was computed.
%% tmp %% A node limit of 10 million was set; runs with more than 10 million recursive calls
%% tmp %% were counted as requiring 10 million calls.
%% tmp %% (Similar heatmaps for the Glasgow Subgraph Solver comparing the first and last of the strategies shown were
%% tmp %% presented by McCreesh et al.\ \cite{DBLP:journals/jair/McCreeshPST18}.  Moreover,
%% tmp %% that paper shows that there is a strong relationship between the optimal strategy
%% tmp %% and the location of the phase transition between unsatisfiable and satisfiable
%% tmp %% instances.
%% tmp %% The results of McCreesh et al.\ show similar patterns to those shown here for \McSplit-SI.)
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][Pattern order 8] {
%% tmp %%         \centering
%% tmp %%         \includegraphics*[width=0.92\textwidth]{14b-mcsplit-induced-si/deg_sorting_experiment_fine_grained/img/heatmap_sip8.pdf}
%% tmp %%         \label{figure:sip-heatmap-8}
%% tmp %%     }
%% tmp %%     \subfigure[][Pattern order 12] {
%% tmp %%         \centering
%% tmp %%         \includegraphics*[width=0.92\textwidth]{14b-mcsplit-induced-si/deg_sorting_experiment_fine_grained/img/heatmap_sip12.pdf}
%% tmp %%         \label{figure:sip-heatmap-12}
%% tmp %%     }
%% tmp %%     \subfigure[][Pattern order 16] {
%% tmp %%         \centering
%% tmp %%         \includegraphics*[width=0.92\textwidth]{14b-mcsplit-induced-si/deg_sorting_experiment_fine_grained/img/heatmap_sip16.pdf}
%% tmp %%         \label{figure:sip-heatmap-16}
%% tmp %%     }
%% tmp %%     \subfigure[][Colour key (search effort divided by search effort of best strategy)] {
%% tmp %%         \centering
%% tmp %%         \includegraphics*[width=0.6\textwidth]{14b-mcsplit-induced-si/deg_sorting_experiment_fine_grained/img/key.pdf}
%% tmp %%         \label{figure:sip-heatmap-key}
%% tmp %%     }
%% tmp %%     \caption{Heatmaps of search effort compared to the best strategy, varying pattern density
%% tmp %%     (horizontal axis) and target density (vertical axis)}\label{figure:sip-heatmaps}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% The heatmaps in \Cref{fig:sip-heatmaps} show which pairing of variable and value
%% tmp %% ordering heuristics was best for each pattern density - target density pair.  To explain
%% tmp %% the plots, we refer to the first of the four squares in \Cref{figure:sip-heatmap-8}
%% tmp %% as an example.  On the $x$ and $y$ axes, we have values of the graph generator's $p$
%% tmp %% (density) parameter ranging from 0 to 1 for the pattern
%% tmp %% and target graph respectively.  The plot shows, for each pair of density
%% tmp %% parameters, how the combination of ``G increasing'' variable-ordering tie breaker
%% tmp %% and ``H increasing'' value-ordering heuristic compares with the best of the four
%% tmp %% possible strategies.  Dark blue indicates that ``G increasing, H increasing'' is
%% tmp %% the best strategy, mid blue indicates that it requires between 1 and 2 times the search
%% tmp %% effort of the best strategy, and light blue indicates that it requires between 2 and
%% tmp %% 10 times the search effort of the best strategy.  From this subplot we can see that,
%% tmp %% for random graphs with pattern order 8 and target order 80, the ``G increasing,
%% tmp %% H increasing'' strategy appears to be preferable to the other three strategies
%% tmp %% if the density of the target graph exceeds that of the pattern graph.
%% tmp %% 
%% tmp %% The first subplot of
%% tmp %% \Cref{figure:sip-heatmap-8}
%% tmp %% shows that the ``G decreasing, H decreasing'' strategy is
%% tmp %% preferable if the density of the target graph is less than that of the pattern graph.
%% tmp %% The two middle subplots are predominantly lighter blues and white, implying that
%% tmp %% using opposite variable and value ordering heuristics is only of benefit in small
%% tmp %% parts of the parameter space.
%% tmp %% 
%% tmp %% \Cref{figure:sip-heatmap-16} --- with pattern graphs of order 16 --- has a somewhat different
%% tmp %% pattern.  Now, the ``G increasing'' tie-break for the value ordering heuristic
%% tmp %% appear to be preferable in most cases where the target density exceeds $0.5$.  This is equivalent
%% tmp %% to preferring pattern vertices that are involved in as few constraints as possible.
%% tmp %% 
%% tmp %% A clear message from these figures is that the optimal choice of variable and
%% tmp %% value ordering heuristic depends on the characteristics of an instance in a
%% tmp %% complex way.
%% tmp %% In the experimental evaluation in (TODO say which section), I consider two 
%% tmp %% strategies which broadly extrapolate from the results in
%% tmp %% \Cref{figure:sip-heatmap-8} and
%% tmp %% \Cref{figure:sip-heatmap-16}.  The first strategy is to use ``G increasing, H increasing''
%% tmp %% if the target density is greater than the pattern density, and ``G decreasing, H decreasing''
%% tmp %% otherwise.  The second strategy is to use ``G increasing, H increasing if the target
%% tmp %% density is greater than $0.5$, and ``G decreasing, H decreasing'' otherwise.
%% tmp %% In practice, my suggestion is that it would be useful to choose
%% tmp %% variable and value ordering heuristics empirically based on a subset of the family
%% tmp %% of instances to be solved, and perhaps even to try running multiple heuristics
%% tmp %% in parallel.
%% tmp %% 
%% tmp %% \subsection{Static variable ordering heuristics}
%% tmp %% 
%% tmp %% So far in this section, we have considered only \emph{dynamic} variable ordering heuristics,
%% tmp %% in which the choice of $v$ is made during search and takes into account the current
%% tmp %% sizes of label classes.  The RI solver, which does not use the concept of domains,
%% tmp %% takes a simpler approach \cite{DBLP:journals/tcbb/BonniciG17}; a static variable order
%% tmp %% is used, which is determined before search.  One advantage of this is speed per recursive
%% tmp %% call --- no effort beyond a constant-time lookup is required to choose the next variable.
%% tmp %% The RI order is generated one element at a time, maintaining three sets.  The first, $X_1$,
%% tmp %% contains pattern-graph vertices already in the order. The second, $X_2$, contains vertices
%% tmp %% not in $X_1$ but adjacent to at least one element of $X_1$.  The third set, $X_3$, contains
%% tmp %% all remaining pattern vertices.  At each step, the next element of the order is chosen
%% tmp %% by selecting a vertex with as many neighbours in $X_1$ as possible, tie-breaking by
%% tmp %% the number of neighbours in $X_2$, then finally tie-breaking by the number of neighbours
%% tmp %% in $X_3$.
%% tmp %% 
%% tmp %% TODO say that RI maybe approximates dom+deg. Say that I've implemented RI heur (just
%% tmp %% for undirected), but for dense graphs I do the heuristic on the complements.
%% tmp %% 
%% tmp %% \section{Generalised arc consistency on the all-different constraint}
%% tmp %% 
%% tmp %% The constraint programming model for induced subgraph isomorphism contains an all-different
%% tmp %% constraint over all the variables; this constraint ensures that each of the pattern-graph vertices
%% tmp %% is mapped to a distinct vertex in the target graph.  The strongest level of consistency that can
%% tmp %% be achieved for this constraint is \emph{generalised arc consistency (GAC)} (TODO define GAC).
%% tmp %% The classic algorithm for achieving GAC on an all-different constraint is R\'egin's
%% tmp %% \cite{DBLP:conf/aaai/Regin94}, which operates
%% tmp %% on a (perhaps implicit) bipartite graph with variables on the left and values on the right, and 
%% tmp %% deletes every edge that does not appear in any maximum matching.  The algorithm operates by computing
%% tmp %% a maximum matching on the bipartite graph, then finding strongly connected components on an related directed
%% tmp %% graph.  Many optimisations to the algorithm have been proposed since its introduction; see
%% tmp %% \cite{DBLP:journals/ai/GentMN08} for a detailed review and empirical study.
%% tmp %% 
%% tmp %% The Glasgow Subgraph Solver \cite{DBLP:conf/cp/McCreeshP15} introduces a new propagation algorithm,
%% tmp %% the \emph{counting all-different propagator}.
%% tmp %% The algorithm iterates over the domains involved in the constraint, maintaining a set $A$ containing
%% tmp %% all values seen so far.  If, at any step during the algorithm, $|A|$ is smaller than the number
%% tmp %% of domains visited so far, the algorithm can backtrack.  If $|A|$ equals the number of domains visited
%% tmp %% so far, then all of the members of $A$ are added to a set $H$ (the \emph{Hall set}), and are deleted from
%% tmp %% the domains of subsequently-visited variables.\footnote{To simplify the presentation,
%% tmp %% I have made trivial changes from the algorithm described by McCreesh and Prosser.
%% tmp %% These changes affect neither the results nor the time complexity of the propagation algorithm.}
%% tmp %% The order in which variables are visited is crucial
%% tmp %% to the algorithm's effectiveness in practice; McCreesh and Prosser
%% tmp %% propose visiting variables in increasing order of domain size in order to keep the set $A$ small.
%% tmp %% 
%% tmp %% The counting all-different propagator provides weaker filtering than
%% tmp %% R\'egin's propagator: it never deletes more values from domains than R\'egin's algorithm, and sometimes
%% tmp %% deletes fewer. Nevertheless, McCreesh and Prosser showed that it runs many times faster than
%% tmp %% R\'egin's algorithm and its filtering is almost as effective as that of R\'egin's algorithm in practice
%% tmp %% on a large set of benchmark instances.
%% tmp %% 
%% tmp %% This section has two contributions. First, we show that \McSplit-SI achieves generalised arc consistency
%% tmp %% on the all-different constraint for free, without requiring an all-different propagator.
%% tmp %% Second, as an existence proof that this can provide benefits beyond those of the counting all-different
%% tmp %% propagator, we describe
%% tmp %% a family of instances that cannot be solved efficiently by Glasgow --- or indeed by RI --- but can
%% tmp %% be solved very quickly by \McSplit-SI.
%% tmp %% 
%% tmp %% \subsection{\McSplit-SI achieves GAC}
%% tmp %% 
%% tmp %% In \Cref{gacProposition}, we view the label classes as a domain store in which each label
%% tmp %% class $\langle V_G, V_H \rangle$ represents a set of $|V_G|$ variables, each with domain $V_H$,
%% tmp %% and show that \McSplit-SI maintains GAC.  The proof depends on the fact that domains in
%% tmp %% \McSplit-SI are guaranteed to be
%% tmp %% either equal or disjoint, and also on the fact that \McSplit-SI backtracks if $|V_G| > |V_H|$
%% tmp %% for any label class.
%% tmp %% 
%% tmp %% \begin{proposition}\label{gacProposition}
%% tmp %%     \McSplit-SI maintains generalised arc consistency on the all-different constraint
%% tmp %% \end{proposition}
%% tmp %% 
%% tmp %% \begin{proof}
%% tmp %% Let $\langle V_G^1, V_H^1 \rangle, \dots, \langle V_G^k, V_H^k \rangle$ be the list of
%% tmp %% label classes.  From (a previous chapter) \Cref{c:mcsplit-i-undirected}, we have that $|V_G^i| \leq |V_H^i|$
%% tmp %% for $1 \leq i \leq k$ and that $V_H^i \cap V_H^j = \emptyset$ for $i \not= j$.
%% tmp %% 
%% tmp %% Let $v \in V_G^i$ and $w \in V_H^i$ for some $1 \leq i \leq k$.  We need to show that we
%% tmp %% extend the mapping
%% tmp %% $(v,w)$ to a complete assignment of the vertices in all $V_G^j$ ($1 \leq j \leq k$).
%% tmp %% This can be achieved by assiging, for each $j$ ($1 \leq j \leq k$) the vertices of
%% tmp %% $V_G^j \setminus \{v\}$ to any $|V_G^j \setminus \{v\}|$ vertex subset of
%% tmp %% $V_H^j \setminus \{w\}$.
%% tmp %% \end{proof}
%% tmp %% 
%% tmp %% \subsection{A family of instances where \McSplit-SI outperforms other algorithms}
%% tmp %% 
%% tmp %% In this subsection, we consider a family of graphs devised to deminstrate
%% tmp %% that the generalised arc consistency achieved by \McSplit-SI can give a dramatic
%% tmp %% speed-up compared to algorithms that do not achieve GAC.
%% tmp %% The instances described here are presented as an existence proof, rather than
%% tmp %% as representative of real-world instances.
%% tmp %% 
%% tmp %% Consider the pattern graph $G_2$ in \Cref{figure:gac-example-3} and the target
%% tmp %% graph $H_2$ in \Cref{figure:gac-example-4}.  This induced subgraph isomorphism
%% tmp %% instance is unsatisfiable: $u$ may only be mapped to $x$ because the other
%% tmp %% vertices in $H_2$ have insufficient degree, after which we can deduce
%% tmp %% that each of the five isolated $w_i$ vertices must be mapped to one of the four
%% tmp %% isolated $z_j$ vertices.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][$G_2$] {
%% tmp %%         \centering
%% tmp %%         \scalebox{1}{
%% tmp %%           \begin{tikzpicture}[scale=0.85, every node/.style={scale=0.85,shape=circle,inner sep=.5pt,
%% tmp %%                   minimum size=5mm}]
%% tmp %%               \node[draw] (u) at (0,1) {$u$};
%% tmp %%               \node[draw] (v1) at (-.6,0) {$v_1$};
%% tmp %%               \node[draw] (v2) at (.6,0) {$v_2$};
%% tmp %%               \node[draw] (w1) at (-1.5,-1) {$w_1$};
%% tmp %%               \node[draw] (w2) at (-.75,-1) {$w_2$};
%% tmp %%               \node[draw] (w3) at (0,-1) {$w_3$};
%% tmp %%               \node[draw] (w4) at (.75,-1) {$w_4$};
%% tmp %%               \node[draw] (w5) at (1.5,-1) {$w_5$};
%% tmp %%               \draw (u) -- (v1);
%% tmp %%               \draw (u) -- (v2);
%% tmp %%           \end{tikzpicture}
%% tmp %%         }
%% tmp %%         \label{figure:gac-example-3}
%% tmp %%     }
%% tmp %%     \subfigure[][$H_2$] {
%% tmp %%         \centering
%% tmp %%         \scalebox{1}{
%% tmp %%           \begin{tikzpicture}[scale=0.85, every node/.style={scale=0.85,shape=circle,inner sep=.5pt,
%% tmp %%                   minimum size=5mm}]
%% tmp %%               \node[draw] (x) at (0,1) {$x$};
%% tmp %%               \node[draw] (y1) at (-1.2,0) {$y_1$};
%% tmp %%               \node[draw] (y2) at (-.4,0) {$y_2$};
%% tmp %%               \node[draw] (y3) at (.4,0) {$y_3$};
%% tmp %%               \node[draw] (y4) at (1.2,0) {$y_4$};
%% tmp %%               \node[draw] (z1) at (-1.2,-1) {$z_1$};
%% tmp %%               \node[draw] (z2) at (-.4,-1) {$z_2$};
%% tmp %%               \node[draw] (z3) at (.4,-1) {$z_3$};
%% tmp %%               \node[draw] (z4) at (1.2,-1) {$z_4$};
%% tmp %%               \draw (x) -- (y1);
%% tmp %%               \draw (x) -- (y2);
%% tmp %%               \draw (x) -- (y3);
%% tmp %%               \draw (x) -- (y4);
%% tmp %%           \end{tikzpicture}
%% tmp %%         }
%% tmp %%         \label{figure:gac-example-4}
%% tmp %%     }
%% tmp %%     \subfigure[][$G_k$] {
%% tmp %%         \centering
%% tmp %%         \scalebox{1}{
%% tmp %%           \begin{tikzpicture}[scale=0.85, every node/.style={scale=0.85,shape=circle,inner sep=.5pt,
%% tmp %%                   minimum size=5mm}]
%% tmp %%               \node[draw] (u) at (0,1) {$u$};
%% tmp %%               \node[draw] (v1) at (-.7,0) {$v_1$};
%% tmp %%               \node[] (vdots) at (0,0) {$\dots$};
%% tmp %%               \node[draw] (v2) at (.7,0) {$v_k$};
%% tmp %%               \node[draw] (w1) at (-.8,-1) {$w_1$};
%% tmp %%               \node[] (wdots) at (0,-1) {$\dots$};
%% tmp %%               \node[draw] (w5) at (.8,-1) {$w_{k+3}$};
%% tmp %%               \draw (u) -- (v1);
%% tmp %%               \draw (u) -- (v2);
%% tmp %%           \end{tikzpicture}
%% tmp %%         }
%% tmp %%         \label{figure:gac-example-1}
%% tmp %%     }
%% tmp %%     \subfigure[][$H_k$] {
%% tmp %%         \centering
%% tmp %%         \scalebox{1}{
%% tmp %%           \begin{tikzpicture}[scale=0.85, every node/.style={scale=0.85,shape=circle,inner sep=.5pt,
%% tmp %%                   minimum size=5mm}]
%% tmp %%               \node[draw] (x) at (0,1) {$x$};
%% tmp %%               \node[draw] (y1) at (-.7,0) {$y_1$};
%% tmp %%               \node[] (ydots) at (0,0) {$\dots$};
%% tmp %%               \node[draw] (y2) at (.7,0) {$y_{k+2}$};
%% tmp %%               \node[draw] (z1) at (-.8,-1) {$z_1$};
%% tmp %%               \node[] (zdots) at (0,-1) {$\dots$};
%% tmp %%               \node[draw] (z5) at (.8,-1) {$z_{k+2}$};
%% tmp %%               \draw (x) -- (y1);
%% tmp %%               \draw (x) -- (y2);
%% tmp %%           \end{tikzpicture}
%% tmp %%         }
%% tmp %%         \label{figure:gac-example-2}
%% tmp %%     }
%% tmp %%     \caption{Example graphs $G_2$ and $H_2$, and their generalised
%% tmp %%     versions $G_k$ and $H_k$.}\label{figure:gac-example}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% When solving this instance, \McSplit-SI begins by mapping $u$ to $x$.  This leaves
%% tmp %% two label classes:
%% tmp %% $\langle \{v_1,v_2\}, \{y_1,y_2,y_3,y_4\} \rangle$
%% tmp %% and
%% tmp %% $\langle \{w_1,w_2,w_3,w_4,w_5\}, \{z_1,z_2,z_3,z_4\} \rangle$.  In the latter
%% tmp %% label class, the set $V_G$ is larger than the set $V_H$, and therefore the
%% tmp %% algorithm can backtrack and terminate.
%% tmp %% 
%% tmp %% Now we consider how the Glasgow algorithm behaves on this instance. After mapping
%% tmp %% $u$ to $x$, the domains correspond to our label classes, as shown in the first two
%% tmp %% columns of \Cref{tab:counting-all-diff}.  The remaining two columns of the table
%% tmp %% illustrate the behaviour of the counting all-different propagator on these domains.
%% tmp %% (Since all domains are of the same size, the stable sort function used by the algorithm
%% tmp %% does not reorder the domains.)  The third column shows set $A$, which is the union
%% tmp %% of domains in the current and previous rows.  The fourth column shows the number
%% tmp %% of variables up to and including the current row.  Since $|A| \geq n$ on each row,
%% tmp %% the propagator does not delete any values from the domains and does not conclude
%% tmp %% that we can backtrack.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \begin{tabular}{p{0.09\linewidth} p{0.16\linewidth} p{0.3\linewidth} p{0.08\linewidth}}
%% tmp %%  \toprule
%% tmp %%      Variable & Domain & $A$ & $n$\\ [0.5ex]
%% tmp %%  \midrule
%% tmp %%      $v_1$ & $\{y_1,y_2,y_3,y_4\}$ & $\{y_1,y_2,y_3,y_4\}$ & 1\\
%% tmp %%      $v_2$ & $\{y_1,y_2,y_3,y_4\}$ & $\{y_1,y_2,y_3,y_4\}$ & 2\\
%% tmp %%      $w_1$ & $\{z_1,z_2,z_3,z_4\}$ & $\{y_1,y_2,y_3,y_4,z_1,z_2,z_3,z_4\}$ & 3\\
%% tmp %%      $w_2$ & $\{z_1,z_2,z_3,z_4\}$ & $\{y_1,y_2,y_3,y_4,z_1,z_2,z_3,z_4\}$ & 4\\
%% tmp %%      $w_3$ & $\{z_1,z_2,z_3,z_4\}$ & $\{y_1,y_2,y_3,y_4,z_1,z_2,z_3,z_4\}$ & 5\\
%% tmp %%      $w_4$ & $\{z_1,z_2,z_3,z_4\}$ & $\{y_1,y_2,y_3,y_4,z_1,z_2,z_3,z_4\}$ & 6\\
%% tmp %%      $w_5$ & $\{z_1,z_2,z_3,z_4\}$ & $\{y_1,y_2,y_3,y_4,z_1,z_2,z_3,z_4\}$ & 7\\
%% tmp %% %    $s_G$ & Pointer to Integer & Pointer to the first vertex of the $G$-set\\
%% tmp %% %    \rule{0pt}{2.3ex}$e_G$ & Pointer to Integer & Pointer to one element past the last vertex of the $G$-set\\
%% tmp %%  \bottomrule
%% tmp %% \end{tabular}
%% tmp %% \caption{A demonstration of the counting all-different propagator on $G_2$ and $H_2$
%% tmp %%     after assigning $u$ to $x$.}
%% tmp %% \label{tab:counting-all-diff}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% The final two graphs in \Cref{figure:gac-example} generalise $G_2$ and $H_2$; as $k$ is incremented,
%% tmp %% a vertex is added to each of the $v$, $w$, $y$ and $z$ sets.
%% tmp %% \Cref{tab:gk-run-times} shows run times for the enumeration problem
%% tmp %% using \McSplit-SI, Glasgow, Glasgow with no supplemental graphs, and RI for a range of values of $k$.
%% tmp %% VF3 was excluded from the experiment because the current version does not handle disconnected graphs correctly.
%% tmp %% \McSplit-SI solves the instance $k=1\,000\,000$ in less than a second;
%% tmp %% Glasgow and RI time out on the $k=10$ and $k=6$ instances respectively.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \begin{tabular}{r r r r r}
%% tmp %%  \toprule
%% tmp %%         $k$ & \McSplit-SI & Glasgow & Glasgow-NS& RI \\ % [0.5ex]
%% tmp %%  \midrule
%% tmp %%         3 &  0 &  0 &  0 &  2\\
%% tmp %%         4 &  0 &  0 &  0 &  86\\
%% tmp %%         5 &  0 &  2 &  2 &  4305\\
%% tmp %%         6 &  0 &  21 &  19 &  *\\
%% tmp %%         7 &  0 &  195 &  191 &  *\\
%% tmp %%         8 &  0 &  2083 &  1966 &  *\\
%% tmp %%         9 &  0 &  24254 &  23443 &  *\\
%% tmp %%         10 &  0 &  * &  * &  *\\
%% tmp %%         10000 &  6 & * & * & *\\
%% tmp %%         100000 &  66 & * & * & *\\
%% tmp %%         1000000 &  676 & * & * & *\\
%% tmp %%  \bottomrule
%% tmp %% \end{tabular}
%% tmp %% \caption{Run times in ms for the induced subgraph isomorphism enumeration problem on $G_k$ and $H_k$.
%% tmp %%     An asterisk indicates timeout at 100 seconds. Glasgow-NS is the Glasgow Subgraph Solver
%% tmp %%     with supplemental graphs disabled.}
%% tmp %% \label{tab:gk-run-times}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \subsection{A family of instances where \McSplit-SI is outperformed by Glasgow}
%% tmp %% 
%% tmp %% In the previous subsection, we saw a family of instances on which \McSplit-SI easily outperforms
%% tmp %% the Glasgow Subgraph Solver.  We can easily construct a family of instances where the reverse is true.
%% tmp %% Consider the graphs in \Cref{figure:glasgow-fast-example}.
%% tmp %% Graph $G'_3$ consists of three copies of the cycle $C_4$ and three copies of the star
%% tmp %% $K_{1,3}$, with no additional edges.  Graph $H'_3$ consists of three copies of $C_5$
%% tmp %% and three copies of $K_{1,3}$.  We generalise these definition to $G'_k$ and $H'_k$,
%% tmp %% which have $k$ copies the cycle and star rather than 3.
%% tmp %% For $k\geq 1$, no instance $(G'_k, H'_k)$ is satisfiable, since $H'_k$ does not contain
%% tmp %% an induced 4-cycle.
%% tmp %% 
%% tmp %% The \McSplit-SI algorithm prefers to map high-degree vertices first, and therefore its first
%% tmp %% decisions on these instances involves the stars rather than the cycles.  Only at deeper
%% tmp %% levels of the search
%% tmp %% tree, when all of the stars have been mapped, does the algorithm begin to work on the cycles,
%% tmp %% at which point it can backtrack.  Unfortunately, there are $6^k k!$ ways to map the stars
%% tmp %% of $G'_k$ to the stars of $H'_k$, since any star in the pattern graph can be mapped to any
%% tmp %% star in the target graph and there are six possible ways to map the leaf nodes of any star.
%% tmp %% Therefore \McSplit-SI's search tree is very large even
%% tmp %% for small values of $k$.
%% tmp %% 
%% tmp %% With supplemental graphs disabled, the Glasgow algorithm suffers from the same problem.
%% tmp %% However, supplemental graphs allow the Glasgow Subgraph Solver to solve these instances
%% tmp %% without search.  In particular, consider the supplemental graph in which $v$ and $w$
%% tmp %% are adjacent
%% tmp %% if and only there are at least two 2-paths between $v$ and $w$ in the original graph.
%% tmp %% This supplemental graph
%% tmp %% contains edges between vertices of the 4-cycles in the pattern graph, but has no edges for the
%% tmp %% target graph.
%% tmp %% 
%% tmp %% \Cref{tab:gk-prime-run-times} shows that supplemental graphs make a huge
%% tmp %% difference to Glasgow's run times in practice on this family of instances.  The
%% tmp %% table shows times for \McSplit-SI, Glasgow, Glasgow without supplemental
%% tmp %% graphs, and RI.  \McSplit-SI and RI have similar run times, and cannot solve
%% tmp %% instances with $k$ greater than 5 within the 100 second time limit.  Glasgow can
%% tmp %% solve the instance with $k=1000$ (a 7000-vertex pattern graph and an
%% tmp %% 8000-vertex target graph) in less than 4 seconds.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][$G'_3$] {
%% tmp %%         \centering
%% tmp %%         \scalebox{1}{
%% tmp %%           \foreach \n in {1,...,3}{
%% tmp %%               \begin{tikzpicture}[scale=0.75, every node/.style={scale=0.75,shape=circle,inner sep=.5pt,
%% tmp %%                       minimum size=3mm}]
%% tmp %%                   \node[draw] (a) at (0,0) {};
%% tmp %%                   \node[draw] (b) at (.5,.5) {};
%% tmp %%                   \node[draw] (c) at (1,0) {};
%% tmp %%                   \node[draw] (d) at (.5,-.5) {};
%% tmp %%                   \node[draw] (e) at (.5,-1) {};
%% tmp %%                   \node[draw] (f) at (0,-1.6) {};
%% tmp %%                   \node[draw] (g) at (.5,-1.7) {};
%% tmp %%                   \node[draw] (h) at (1,-1.6) {};
%% tmp %%                   \draw (a) -- (b) -- (c) -- (d) -- (a);
%% tmp %%                   \draw (e) -- (f);
%% tmp %%                   \draw (e) -- (g);
%% tmp %%                   \draw (e) -- (h);
%% tmp %%               \end{tikzpicture}
%% tmp %%           }
%% tmp %%         }
%% tmp %%     }
%% tmp %%     \subfigure[][$H'_3$] {
%% tmp %%         \centering
%% tmp %%         \scalebox{1}{
%% tmp %%           \foreach \n in {1,...,3}{
%% tmp %%               \begin{tikzpicture}[scale=0.75, every node/.style={scale=0.75,shape=circle,inner sep=.5pt,
%% tmp %%                       minimum size=3mm}]
%% tmp %%                   \node[draw] (z) at (0.5,0.55) {};
%% tmp %%                   \node[draw] (a) at (-0.02,0.17) {};
%% tmp %%                   \node[draw] (b) at (0.18,-0.44) {};
%% tmp %%                   \node[draw] (c) at (0.82,-0.44) {};
%% tmp %%                   \node[draw] (d) at (1.02,0.17) {};
%% tmp %%                   \node[draw] (e) at (.5,-1) {};
%% tmp %%                   \node[draw] (f) at (0,-1.6) {};
%% tmp %%                   \node[draw] (g) at (.5,-1.7) {};
%% tmp %%                   \node[draw] (h) at (1,-1.6) {};
%% tmp %%                   \draw (a) -- (b) -- (c) -- (d) -- (z) -- (a);
%% tmp %%                   \draw (e) -- (f);
%% tmp %%                   \draw (e) -- (g);
%% tmp %%                   \draw (e) -- (h);
%% tmp %%               \end{tikzpicture}
%% tmp %%           }
%% tmp %%         }
%% tmp %%     }
%% tmp %%     \caption{Example graphs $G'_3$ and $H'_3$.}\label{figure:glasgow-fast-example}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \begin{tabular}{r r r r r}
%% tmp %%  \toprule
%% tmp %%      $k$ & \McSplit-SI & Glasgow & Glasgow-NS& RI \\ %[0.5ex]
%% tmp %%  \midrule
%% tmp %%      1 &  0 &  0 &  0 &  0\\
%% tmp %%      2 &  0 &  0 &  1 &  0\\
%% tmp %%      3 &  10 &  0 &  47 &  10\\
%% tmp %%      4 &  329 &  0 &  1793 &  324\\
%% tmp %%      5 &  12522 &  0 &  80880 &  11987\\
%% tmp %%      6 &  * &  0 &  * &  *\\
%% tmp %%      7 &  * &  0 &  * &  *\\
%% tmp %%      8 &  * &  0 &  * &  *\\
%% tmp %%      9 &  * &  0 &  * &  *\\
%% tmp %%      10 &  * &  0 &  * &  *\\
%% tmp %%      100 &  * &  27 &  * &  *\\
%% tmp %%      1000 &  * &  3825 &  * &  *\\
%% tmp %%  \bottomrule
%% tmp %% \end{tabular}
%% tmp %% \caption{Run times in ms for the induced subgraph isomorphism enumeration problem on $G'_k$ and $H'_k$.
%% tmp %%     An asterisk indicates timeout at 100 seconds. Glasgow-NS is the Glasgow Subgraph Solver
%% tmp %%     with supplemental graphs disabled.}
%% tmp %% \label{tab:gk-prime-run-times}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% As we have seen in this section, neither \McSplit-SI nor Glasgow dominates the other solver.  In the next
%% tmp %% section, we perform an experimental evalulation to compare solvers on benchmark instances.
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \section{A version using linked lists of vertices}
%% tmp %% 
%% tmp %% The data structure used by \McSplit-SI to represent the two lists of vertices
%% tmp %% within each label class enables fast partitioning, but has the disadvantage
%% tmp %% that the vertices in each list are not kept in any particular order.  This has
%% tmp %% two negative consequences.  First, when selecting a label class according to
%% tmp %% the smallest domain first heuristic with tie breaking on degree, we need to
%% tmp %% scan the pattern-graph vertices within each label class of minimum size to find
%% tmp %% a vertex of optimal degree.  Second, we face a time-space tradeoff when
%% tmp %% iterating over the target-graph vertices in degree order on
%% tmp %% \lineref{McSplitSIWLoop} of \Cref{McSplitSIAlg}: we can choose either to copy
%% tmp %% the list of vertices representing $S_H$ and then sort this copy, or to scan the
%% tmp %% list $S_H$ on each iteration for the next-best element.  The first of these
%% tmp %% options --- which we use in our implementation --- requires $O(|S_H| \log
%% tmp %% |S_H|)$ time and $|S_H|$ words of additional space; the second requires
%% tmp %% $O(|S_H|^2)$ time and no additional space.
%% tmp %% 
%% tmp %% These disadvantages tend to be small in practice, as the label class chosen for
%% tmp %% iteration tends to be small except at the root of the search tree.
%% tmp %% Nevertheless, there exist pathological instances in which the smallest label
%% tmp %% classes are large even deep in the search tree.  For example, if the pattern
%% tmp %% and target graphs have no edges then there is only one label class at every
%% tmp %% depth of recursion.  Therefore, it would be useful to have a version of
%% tmp %% \McSplit-SI that keeps the vertices sorted in each label class without increasing
%% tmp %% the time complexity of the partitioning procedure.  This section describes
%% tmp %% such a version, which we call \McSplit-SI-LL because it stores
%% tmp %% vertices in linked lists.
%% tmp %% 
%% tmp %% The data structures of \McSplit-SI-LL differ from those of \McSplit-SI as
%% tmp %% follows.  \McSplit-SI-LL does not use the arrays \Garray\ and \Harray; rather,
%% tmp %% each element of \Gptrs\ and \Hptrs\ has forward and backward pointers that
%% tmp %% enable the vertices within a label class to be joined together as a doubly
%% tmp %% linked list.  In each label class, \varStartG, \varEndG, \varStartH, and
%% tmp %% \varEndH\ point to the first and last nodes of these linked lists in \Gptrs\
%% tmp %% and \Hptrs.  Each label class has two additional integer members that store the
%% tmp %% lengths of the two lists of vertices.
%% tmp %% 
%% tmp %% Since the linked-list nodes are embedded in an array, we can delete a given
%% tmp %% vertex from its list in constant time.  We have the usual time complexity
%% tmp %% guarantees of doubly linked lists for other operations: constant-time
%% tmp %% append and insert, and linear-time iteration.
%% tmp %% 
%% tmp %% \Cref{figure:si-data-structures-ll-version}
%% tmp %% shows the data structures of \McSplit-SI-LL after assigning vertex $1$ to vertex $a$;
%% tmp %% this corresponds to \Cref{figure:si-data-structures} which shows the same state
%% tmp %% using the data structures of \McSplit-SI.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \includegraphics*[width=0.9\textwidth]{14b-mcsplit-induced-si/figs/data-structure-step-1-ll-version}
%% tmp %%     \caption{TODO}
%% tmp %%     \label{figure:si-data-structures-ll-version}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% Before the first call to $\FuncSty{Search}()$, the two linked lists of vertices in
%% tmp %% each label class are sorted in order of vertex degree.  We also sort each adjacency list
%% tmp %% of graphs $G$ and $H$ in order of vertex degree.
%% tmp %% 
%% tmp %% We require the order of each linked list of vertices to be maintained
%% tmp %% by the $\FuncSty{Filter}$ and $\FuncSty{Unfilter}$ functions.  The first of these is straightforward:
%% tmp %% when iterating over an adjacency list in the $\FuncSty{Filter}$ function, we delete each vertex $v$
%% tmp %% from its label class and append it to the new label class.  Because the adjacency lists have been sorted
%% tmp %% by degree before search, vertices are appended to each new label class in order of degree.
%% tmp %% 
%% tmp %% The $\FuncSty{Unfilter}$ function requires more work in \McSplit-SI-LL than in \McSplit-SI,
%% tmp %% since when merging label classes we must ensure that each vertex is returned to the position
%% tmp %% in its former label class from which it was removed.  To enable this, we perform a little extra
%% tmp %% bookkeeping during the $\FuncSty{Filter}$ function: each time we remove a vertex $u$, we store
%% tmp %% $v$ in an array along with a pointer to its successor node in the linked list from which $u$
%% tmp %% was removed.  This array is at most as long $|N_G(v)|$ or $|N_H(v)|$, and the storage
%% tmp %% space for all of these arrays can be pre-allocated before search.
%% tmp %% 
%% tmp %% In the next section, we will see that \McSplit-SI-LL is space-efficient.  The experimental evaluation
%% tmp %% in the following section shows that \McSplit-SI-LL runs faster \McSplit-SI on some instances, but
%% tmp %% slightly slower on many instances.
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \section{Space complexity}
%% tmp %% 
%% tmp %% The following proposition demonstrates that the memory needed by \McSplit-SI-LL
%% tmp %% is bounded above by a constant multiple of the space used to store the adjacency
%% tmp %% lists of $G$ and $H$.  While this is greater than the space complexity of 
%% tmp %% VF3 and RI, which require only $|V(G)| + |V(H)|$ space, it is improvement
%% tmp %% over all previous constraint programming algorithms, which
%% tmp %% require at least $O(|V(G)| |V(H)|)$ space just to represent
%% tmp %% the initial domains.  The Glasgow Subgraph Solver uses $O(|V(H)|)$ space
%% tmp %% to represent adjacency matrices, and requires $O(|V(G)|^2|V(H)|)$ space
%% tmp %% to solve any satisfiable instance.
%% tmp %% 
%% tmp %% \begin{proposition}\label{mcsplit-si-space}
%% tmp %%     \McSplit-SI-LL uses $O(n_G + m_G + m_H)$ space, where
%% tmp %%     $n_G=|V(G)|$,
%% tmp %%     $m_G=|E(G)|$, and
%% tmp %%     $m_H=|E(H)|$.
%% tmp %% \end{proposition}
%% tmp %% 
%% tmp %% \begin{proof}
%% tmp %%     The function $\FuncSty{Filter}(v,w)$ runs in $O(|N_G(v)| + |N_H(w)|)$ time
%% tmp %%     and each of its operations allocates at most $O(1)$ space; therefore the
%% tmp %%     function uses $O(|N_G(v)| + |N_H(w)|)$ space.
%% tmp %% 
%% tmp %%     Each of the functions
%% tmp %%     $\FuncSty{SelectLabelClass}$,
%% tmp %%     $\FuncSty{SelectVertex}$,
%% tmp %%     $\FuncSty{Assign}$,
%% tmp %%     $\FuncSty{Unassign}$,
%% tmp %%     and
%% tmp %%     $\FuncSty{Unfilter}$
%% tmp %%     uses $O(1)$ space and does not allocate any memory that is not released
%% tmp %%     when the function returns.  Moreover, $\FuncSty{Unfilter}$ releases
%% tmp %%     all of the memory that was allocated by the corresponding call to $\FuncSty{Filter}$.
%% tmp %% 
%% tmp %%     The mapping $M$ can be no larger than $n_G$, so the maximum recursion depth for
%% tmp %%     $\FuncSty{Search}$ calls is $n_G + 1$.  Now suppose we at the start of the
%% tmp %%     $\FuncSty{Search}$ function at some given node at depth $k$ of the search tree 
%% tmp %%     ($k \leq n_G + 1$).  At earlier levels of the call stack, $k-1$ calls to $\FuncSty{Filter}$
%% tmp %%     have been made; the $v$ parameter for these calls has taken distinct values
%% tmp %%     $\{v_1, \dots, v_{k-1}\} \subseteq V(G)$, and the $w$ parameter has taken distinct values
%% tmp %%     $\{w_1, \dots, w_{k-1}\} \subseteq V(H)$.  These $\FuncSty{Filter}$ calls have used
%% tmp %%     $\sum_{i=1}^{k-1} O(|N_G(v_i)| + |N_H(w_i)|) = O(m_G + m_H)$ space.  In total,
%% tmp %%     local variables used in the $k$
%% tmp %%     recursive calls of $FuncSty{Search}$ use a further $O(k) = O(n_G)$ space.  Thus,
%% tmp %%     the total space usage is $O(n_G + m_G + m_H)$.
%% tmp %% \end{proof}
%% tmp %% 
%% tmp %% \section{Experimental evaluation}
%% tmp %% 
%% tmp %% In this section, we compare the speed of \McSplit-SI with three state-of-the-art algorithms
%% tmp %% on three sets of benchmark instances.  In \Cref{subsec:si-decision-experiment},
%% tmp %% we use an existing large, heterogeneous set of pairs of unlabelled
%% tmp %% graphs.
%% tmp %% In \Cref{subsec:si-knights-experiment},
%% tmp %% we consider a new set of decision-problem
%% tmp %% instances recently proposed by Donald Knuth based on a generalisation of the knight's
%% tmp %% tour problem.
%% tmp %% Finally, in \Cref{subsec:si-enumeration-experiment}, we use pairs of random directed
%% tmp %% graphs based on another existing benchmark set;
%% tmp %% we solve the problem of counting all induced subgraph isomorphisms from the pattern to the target.
%% tmp %% 
%% tmp %% \subsection{Other solvers}
%% tmp %% 
%% tmp %% Our experiments compare \McSplit-SI with three state-of-the-art subgraph isomorphism solvers:
%% tmp %% VF3, RI, and Glasgow.  
%% tmp %% 
%% tmp %% In terms of effort per search node, \McSplit-SI may be viewed intuitively as sitting
%% tmp %% between Glasgow on one hand VF3 and RI on the other.
%% tmp %% 
%% tmp %% \paragraph*{\McSplit-SI-adjmat} Finally, we implemented a version of \McSplit\
%% tmp %% for subgraph isomorphism that stores graphs as adjacency matrices rather than
%% tmp %% adjacency lists.  This does not use the \McSplit-SI data structures described
%% tmp %% in this chapter, and is essentially a decision version of the \McSplit\ solver
%% tmp %% for maximum common subgraph described in \label{c:mcsplit-i-undirected}.
%% tmp %% However, we tried to make the implementation fast, and indeed we will see in
%% tmp %% the results that the algorithm often outperforms \McSplit-SI on instances with
%% tmp %% relatively dense graphs.  The main additional feature compared to the maximum
%% tmp %% common subgraph version of \McSplit is a version of the lazy partitioning
%% tmp %% technique that was described in \Cref{subsec:lazy-partitioning}.  Before
%% tmp %% running the partitioning algorithm, we iterate over the label classes, counting
%% tmp %% in each label class the number of vertices adjacent to $v$ in the pattern graph
%% tmp %% and to $w$ in the target class.  This often allows us to backtrack without the
%% tmp %% need for the relatively expensive step of swapping vertices within a label
%% tmp %% class.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%  \begin{tabular}{p{0.18\linewidth} p{0.75\linewidth} }
%% tmp %%  \toprule
%% tmp %%     Name & Description \\ [0.5ex]
%% tmp %%  \midrule
%% tmp %%     \McSplit-SI & The base \McSplit-SI algorithm \\
%% tmp %%     \rule{0pt}{2.3ex}\McSplit-SI-LL & \McSplit-SI with lists of vertices stored as sorted doubly-linked lists \\
%% tmp %%     \rule{0pt}{2.3ex}\McSplit-SI-AM & An adaptation of \McSplit\ decision-problem solver (using adjacence matrix
%% tmp %%         representation of graphs) to the induced subgraph isomorphism problem.  This does not use \McSplit-SI's
%% tmp %%         partitioning algorithm optimised for sparse graphs. \\
%% tmp %%     \rule{0pt}{2.3ex}\McSplit-SI-s & \McSplit-SI with the dynamic variable-ordering heuristic replaced by
%% tmp %%         the static heuristic of RI, described in TODO cite \\
%% tmp %%     \rule{0pt}{2.3ex}\McSplit-SI-pre & TODO, refer forward. \\
%% tmp %% \bottomrule
%% tmp %% \end{tabular}
%% tmp %% \caption{Summary of \McSplit-SI variants used in this chapter's experiments}
%% tmp %% \label{tab:mcsplit-si variants}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \subsection{Decision instances}\label{subsec:si-decision-experiment}
%% tmp %% 
%% tmp %% Our first set of benchmark instances is
%% tmp %% a collection of $14,621$ pairs of undirected, unlabelled graphs.
%% tmp %% This collection was used by \citet{DBLP:conf/cpaior/ArchibaldDHMP019},
%% tmp %% extending the work of \citet{DBLP:conf/lion/KotthoffMS16};
%% tmp %% it assembles instances from several smaller benchmarks.
%% tmp %% 
%% tmp %% \paragraph*{Families of instances} The benchmark set contains graphs
%% tmp %% in the following families.
%% tmp %% 
%% tmp %% \begin{itemize}
%% tmp %%     \item
%% tmp %%         \textbf{Scalefree:} Randomly generated scale-free graphs \citep{DBLP:books/daglib/0012457}: 80
%% tmp %%         satisfiable instances and 20 unsatisfiable instances.  In each instance,
%% tmp %%         $|V(G)| = 0.9 \times |V(H)|$. Source: \citet{DBLP:journals/constraints/ZampelliDS10}
%% tmp %%     \item
%% tmp %%         \textbf{LV:} Pairs of graphs derived from the Stanford GraphBase \citep{DBLP:books/daglib/0071477}.
%% tmp %%         Source: \cite{DBLP:journals/mscs/LarrosaV02}.
%% tmp %%     \item \textbf{BVG:} Regular and irregular bounded valence target graphs, randomly generated.
%% tmp %%         In the regular instances, the vertices of the target graph have equal degree of 3, 6, or 9
%% tmp %%         depending on the instance.  The irregular instances have variable degree but a fixed total
%% tmp %%         number of edges.
%% tmp %%         This and the following two families are from the database
%% tmp %%         of instances described in \citet{DBLP:journals/prl/SantoFSV03}.  For each instance in these
%% tmp %%         three families, the pattern graphs were generated by taking a random connected
%% tmp %%         induced subgraph of the target graph. All instances in these families are therefore satisfiable.
%% tmp %%     \item \textbf{M4D:} Regular and irregular 4-dimensional meshes.  The irregular instances have
%% tmp %%         extra edges added to the mesh graph.
%% tmp %%     \item \textbf{Rand:} Erd\H{o}s-Rényi $G(n,p)$ random graphs.
%% tmp %%     \item \textbf{Phase:} Pairs of Erd\H{o}s-Rényi $G(n,p)$ random graphs
%% tmp %%         with parameters chosen near the satisfiable/unsatifiable phase transition in order
%% tmp %%         to make the instances very challenging to solve.
%% tmp %%         \citep{DBLP:journals/jair/McCreeshPST18}
%% tmp %%     \item \textbf{PR}, \textbf{Meshes} and \textbf{Images:} Instances derived from a pattern recognition problem, where
%% tmp %%     	the graphs are generated from the adjacencies of regions of an image (PR, Images)
%% tmp %% 	or 3D object model (Meshes). \citep{DBLP:journals/pr/SolnonDHJ15,DBLP:journals/cviu/DamiandSHJS11}
%% tmp %% \end{itemize}
%% tmp %% 
%% tmp %% \Cref{tab:instance-family-summary} shows a summary of the instances in each family.
%% tmp %% Most of the graphs are sparse; the LV and Phase families are unusual in that they contain
%% tmp %% some very dense target graphs.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \begin{tabular}{lrrrrrrrrr}
%% tmp %%  \toprule
%% tmp %%         Family & Count & \multicolumn{4}{c}{Pattern graph} & \multicolumn{4}{c}{Target graph} \\
%% tmp %%      \cmidrule(r){3-6}
%% tmp %%      \cmidrule(r){7-10}
%% tmp %%              & & $n_{\min{}}$ & $n_{\max{}}$ & $d_{\min{}}$ & $d_{\max{}}$
%% tmp %%             & $n_{\min{}}$ & $n_{\max{}}$ & $d_{\min{}}$ & $d_{\max{}}$
%% tmp %%             \\ [0.5ex]
%% tmp %%  \midrule
%% tmp %%         \input{14b-mcsplit-induced-si/decision-instances-experiment/experiment/fatanode-results/densities-with-families-summary-table}
%% tmp %% %    1 & 100 & \numrange{200}{1000} & w  \\
%% tmp %% %    \rule{0pt}{2.3ex}X & x & y & z \\
%% tmp %%  \bottomrule
%% tmp %% \end{tabular}
%% tmp %%     \caption{Summary of instance families. The values $n_{\min{}}$ and $n_{\max{}}$
%% tmp %%             are the smallest and largest vertex counts; the values $d_{\min{}}$ and $d_{\max{}}$
%% tmp %%             are the smallest and largest densities.}
%% tmp %% \label{tab:instance-family-summary}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:column(famcol)!=1?NaN:clamp(xcol)):(clamp(ycol)) ls 1 pt 1 ps 0.7 ti 'SF', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:(column(famcol)!=2&&column(famcol)!=11)?NaN:clamp(xcol)):(clamp(ycol)) w p ls 2 pt 2 ps 0.7 ti 'LV', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:(column(famcol)!=3&&column(famcol)!=4)?NaN:clamp(xcol)):(clamp(ycol)) ls 3 pt 3 ps 0.7 ti 'BVG(r)', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:(column(famcol)!=5&&column(famcol)!=6)?NaN:clamp(xcol)):(clamp(ycol)) ls 4 pt 4 ps 0.7 ti 'M4D(r)', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:column(famcol)!=7?NaN:clamp(xcol)):(clamp(ycol)) ls 5 pt 10 ps 0.7 ti 'Rand', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:column(famcol)!=9?NaN:clamp(xcol)):(clamp(ycol)) ls 6 pt 6 ps 0.7 ti 'PR', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:column(famcol)!=12?NaN:clamp(xcol)):(clamp(ycol)) ls 7 pt 8 ps 0.7 ti 'Phase', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:column(famcol)!=13?NaN:clamp(xcol)):(clamp(ycol)) ls 13 pt 14 ps 0.7 ti 'Meshes', \
%% tmp %% %%     plotfile u (c(xcol)==0&&c(ycol)==0?NaN:column(famcol)!=14?NaN:clamp(xcol)):(clamp(ycol)) ls 8 pt 12 ps 0.7 ti 'Images', \
%% tmp %% \paragraph*{Results}
%% tmp %% 
%% tmp %% \Cref{figure:unlabelled-vf-instance-runtimes} shows cumulative plots of instances solved by \McSplit-SI
%% tmp %% and the other algorithms.  To avoid a tangle of overlapping curves, each solver's curve is shown as a dark
%% tmp %% blue line on its own plot, with the curve for \McSplit-SI shown in light blue for comparison on each
%% tmp %% plot.  The solvers can be split into three broad categories.  Constraint programming solvers tend
%% tmp %% to run slowly on the easiest instances but perform well for hard instances.  The two versions of Glasgow
%% tmp %% are in this category; \McSplit-SI-AM has similar results.  Pattern recognition solvers---RI and VF3
%% tmp %% in particular---perform well on easy instances but solve fewer of the hard instances than the constraint
%% tmp %% programming solvers;
%% tmp %% \citet{DBLP:conf/gbrpr/Solnon19} makes a similar observation for these two solver categories.
%% tmp %% Finally, \McSplit-SI and \McSplit-SI-LL perform well on easy instances---indeed, outperforming
%% tmp %% the pattern recognition solvers---while solving almost as many of the hard instances as Glasgow.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][Glasgow] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-mcsplit-glasgow}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Glasgow, no supp.] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-mcsplit-glasgow-nosupp}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][RI] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-mcsplit-ri}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][RI-DS] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-mcsplit-ri-ds}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][VF3] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-mcsplit-vf3}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][\McSplit-SI-LL] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-mcsplit-si-ll}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][\McSplit-SI-AM] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-mcsplit-si-am}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \caption{Cumulative plots of run times for decision instances.  In each subfigure, the algorithm named
%% tmp %%         in the caption is in dark blue and \McSplit-SI is in light blue.}
%% tmp %%     \label{figure:unlabelled-vf-instance-runtimes}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \Cref{figure:si-decision-scatter} shows a scatter plot of run times for each solver, with the run time of
%% tmp %% \McSplit-SI on the horizontal axis in each plot.  \McSplit-SI compares favourably
%% tmp %% to each of the non-\McSplit\ solvers in the first five plots, although each of these has some instances that it can solve
%% tmp %% in less than a second while \McSplit-SI exceeds the time limit; this is likely to be due to a combination
%% tmp %% of different variable and value ordering heuristics and, in the case of Glasgow, stronger filtering.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][Glasgow] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-mcsplit-glasgow}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Glasgow, no supp.] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-mcsplit-glasgow-nosupp}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][RI] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-mcsplit-ri}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][RI-DS] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-mcsplit-ri-ds}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][VF3] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-mcsplit-vf3}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][\McSplit-SI-LL] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-mcsplit-si-ll}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][\McSplit-SI-AM] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-mcsplit-si-am}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \caption{Scatter plots of run times in ms for decision instances.
%% tmp %%             The horizontal and vertical axes show the run times of \McSplit-SI and the
%% tmp %%             solver named in the subfigure caption, respectively.}
%% tmp %%     \label{figure:si-decision-scatter}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% TODO: mention that D1 variant isn't very good.
%% tmp %% TODO: mention that D2 variant has similar results to Glasgow on phase instances.
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% To give a finer-grained look at the performance of the two best solvers overall---\McSplit-SI and
%% tmp %% Glasgow---\Cref{figure:mcsplitsi-scatter-by-family} shows those solvers' run times for each
%% tmp %% instance, with a separate sub-figure for each family of instances.  On the PR, Phase, Meshes,
%% tmp %% and Images families, \McSplit-SI is the clear winner.   On each of
%% tmp %% the remaining five families, \McSplit-SI is the faster solver on most instances, but Glasgow
%% tmp %% is much faster than \McSplit-SI on a small proportion of instances.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][Scalefree] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Scalefree.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][LV] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-LV.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][BVG] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-BVG.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %% 
%% tmp %%     \subfigure[][M4D] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-M4D.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Rand] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Rand.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][PR] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-PR.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %% 
%% tmp %%     \subfigure[][Phase] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Phase.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Meshes] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Meshes.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Images] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Images.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \caption{Run times in ms of \McSplit-SI (horizontal axis) and Glasgow (vertical axis), by family.}
%% tmp %%     \label{figure:mcsplitsi-scatter-by-family}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% On an instance-by-instance basis, does \McSplit-SI typically run faster than
%% tmp %% the best of the other solvers? To answer this question, we calculate the run
%% tmp %% time of the virtual best other solver (VBOS) for each instance
%% tmp %% by taking the lowest run time
%% tmp %% of the five non-\McSplit\ solvers: Glasgow, Glasgow without supplemental graphs, RI, RI-DS, and VF3.
%% tmp %% This VBOS is essentially equivalent to running the constitutent solvers in parallel
%% tmp %% and stopping when the first solver terminates; we can also view it
%% tmp %% as an idealised portfolio solver with an oracle that selects
%% tmp %% the best non-\McSplit\ solver for a given instance.
%% tmp %% 
%% tmp %% \Cref{figure:mcsplitsi-vbs-scatter-by-family} shows the run times of \McSplit-SI
%% tmp %% and VBOS (vertical axis) for each instance.  On six families
%% tmp %% of instances (BVG, Rand, LV, Phase, Images, Meshes), the number
%% tmp %% of instances where \McSplit-SI is faster than VBOS is greater than the number of instances where
%% tmp %% the reverse is true. 
%% tmp %% On the other hand, Glasgow certainly does not dominate the other solvers;
%% tmp %% indeed, there are certainly families such as Scalefree
%% tmp %% where \McSplit-SI appears to be worse overall than VBOS.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][Scalefree] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Scalefree-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][LV] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-LV-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][BVG] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-BVG-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %% 
%% tmp %%     \subfigure[][M4D] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-M4D-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Rand] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Rand-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][PR] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-PR-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %% 
%% tmp %%     \subfigure[][Phase] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Phase-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Meshes] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Meshes-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][Images] {
%% tmp %%         \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/by-family/scatter-Images-vbos.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \caption{Run times in ms of \McSplit-SI (horizontal axis) and the virtual best other solver (vertical axis), by family.}
%% tmp %%     \label{figure:mcsplitsi-vbs-scatter-by-family}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \paragraph*{The effect of target graph density}
%% tmp %% When is it better to use \McSplit-SI than \McSplit-SI-AM?
%% tmp %% \Cref{figure:density-runtime-ratio-am} has a point per instance, with target graph density on the x axis and the ratio of the two solvers' run times 
%% tmp %% on the y axis; a ratio below 1 indicates that \McSplit-SI is the faster solver.  Trivial instances and instances where at least one
%% tmp %% solver timed out are excluded.  There is a clear positive relationship between density and ratio of run times.  For most instances of
%% tmp %% density below $0.002$, \McSplit-SI is more than $10$ times faster than \McSplit-SI-AM.  However,
%% tmp %% \McSplit-SI-AM soon begins to catch up as target graph density increases, and becomes the faster solver at a target graph density of around
%% tmp %% $0.1$.\footnote{This analysis was carried out using target graph density because we would expect the target graph to have
%% tmp %% a larger effect on run times than the (smaller) pattern graph.  We also re-created the plot with the x axis showing the proportion
%% tmp %% of all possible edges across pattern \emph{and} target graphs: $(m_G + m_H) / (n_G(n_G-1) + n_H(n_H-1))$,
%% tmp %% where $m_G$ and $n_G$ denote the edge and vertex counts of $G$.  The resulting
%% tmp %% plot was almost identical to \Cref{figure:density-runtime-ratio-am}.}
%% tmp %% 
%% tmp %% \Cref{figure:density-runtime-ratio-glasgow} is a similar plot comparing the run time of \McSplit-SI to that of Glasgow.
%% tmp %% (Note the larger range of values of the y axis.)  For very sparse target graphs with density below around $0.002$,
%% tmp %% \McSplit-SI consistently runs faster than Glasgow---often by more than an order of magnitude.  For most of the
%% tmp %% instances with denser target graphs,
%% tmp %% \McSplit-SI is again the faster algorithm, and this holds true even for very dense graphs which are not well suited
%% tmp %% to \McSplit-SI's data structures.  However, there is a long tail of instances
%% tmp %% for which a combination of Glasgow's restarts and stronger filtering methods results in
%% tmp %% an orders-of-magnitude speedup over \McSplit-SI.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][\McSplit-SI-AM] {
%% tmp %%         \includegraphics*[width=0.5\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/density-runtime-ratio}
%% tmp %%         \label{figure:density-runtime-ratio-am}
%% tmp %%     }\subfigure[][Glasgow] {
%% tmp %%         \includegraphics*[width=0.5\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/density-runtime-ratio-glasgow}
%% tmp %%         \label{figure:density-runtime-ratio-glasgow}
%% tmp %%     }
%% tmp %%     \caption{On the horizontal axis, the target graph density; on the vertical axis, the ratio of \McSplit-SI run time to
%% tmp %%             the run time of the algorithm named in the subfigure caption.
%% tmp %%             Instances where either solver took less than 1 ms or exceeded the time limit are excluded.}
%% tmp %%     \label{figure:density-runtime-ratio}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \paragraph*{Presolve} \cite{DBLP:conf/gbrpr/Solnon19} considers a solver that
%% tmp %% runs VF3 for 100 ms, then switches to Glasgow if a solution is not found. This
%% tmp %% outperforms Glasgow on easy instances while retaining almost all of the benefit
%% tmp %% of Glasgow on hard instances.  Are there pairs of solvers in our experiment
%% tmp %% that work particularly well using such a 100 ms presolve?
%% tmp %% \Cref{tab:si-decision-presolve-counts} shows the number of instances solved
%% tmp %% within 1000 seconds by each pair of solvers, excluding \McSplit-SI-AM and RI-DS
%% tmp %% to save space.  Seven pairs of solvers---each of which used a version of \McSplit-SI
%% tmp %% as the presolver, the main solver, or both---solved more instances than Glasgow,
%% tmp %% which was the single
%% tmp %% best individal solver by this measure with $14,524$ instances solved.
%% tmp %% The best two solver pairs
%% tmp %% each solved $14,546$ instances.  These use \McSplit-SI-static as the main
%% tmp %% solver and either \McSplit-SI or Glasgow without supplemental graphs as the
%% tmp %% presolver.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/decision-instances-experiment/experiment/fatanode-results/presolve-crosstab}
%% tmp %% \caption{Number of instances solved within 1000 seconds using a 100 ms presolve.  Each number
%% tmp %%         refers to a solver that runs the solver named in the row for 100 ms, then switches to the
%% tmp %%         solver named in the column.  Underlined values are greater than the number of instances
%% tmp %%         solved by Glasgow without presolve ($14,524$).}
%% tmp %% \label{tab:si-decision-presolve-counts}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \paragraph*{Number of instances solved}
%% tmp %% TODO talk about how \Cref{tab:si-decision-solved-counts} shows the number of instances
%% tmp %% solved.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/decision-instances-experiment/experiment/fatanode-results/solved-counts}
%% tmp %% \caption{The number of instances in each family that were solved by each solver
%% tmp %%     within the 1000 second time limit.
%% tmp %%     The ``Count'' column shows the total number of instances per family.}
%% tmp %% \label{tab:si-decision-solved-counts}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \paragraph*{Number of for which each solver was the fastest}
%% tmp %% TODO talk about \Cref{tab:si-decision-solved-counts}
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/decision-instances-experiment/experiment/fatanode-results/winner-counts}
%% tmp %% \caption{For each family of instances, the number of instances for which each solver's
%% tmp %%     run time equalled the best run time among all solvers shown.  The second
%% tmp %%     column shows the total number of instances per family.}
%% tmp %% \label{tab:si-decision-winner-counts}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.7\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-presolve}
%% tmp %% %%     \caption{cumulative-presolve}
%% tmp %% %%     \label{figure:cumulative-presolve}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.7\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative}
%% tmp %% %%     \caption{cumulative}
%% tmp %% %%     \label{figure:cumulative}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.7\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/sat-cumulative}
%% tmp %% %%     \caption{sat-cumulative}
%% tmp %% %%     \label{figure:sat-cumulative}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.7\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/unsat-cumulative}
%% tmp %% %%     \caption{unsat-cumulative}
%% tmp %% %%     \label{figure:unsat-cumulative}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.7\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/cumulative-without-disconnected-instances}
%% tmp %% %%     \caption{cumulative-without-disconnected-instances}
%% tmp %% %%     \label{figure:cumulative-without-disconnected-instances}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.45\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/mcsplit-si-vs-adjmat}
%% tmp %% %%     \caption{mcsplit-si-vs-adjmat}
%% tmp %% %%     \label{figure:mcsplit-si-vs-adjmat}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.45\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/mcsplit-si-vs-ll}
%% tmp %% %%     \caption{mcsplit-si-vs-ll}
%% tmp %% %%     \label{figure:mcsplit-si-vs-ll}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.45\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/mcsplit-si-vs-glasgow}
%% tmp %% %%     \caption{mcsplit-si-vs-glasgow}
%% tmp %% %%     \label{figure:mcsplit-si-vs-glasgow}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.45\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/mcsplit-si-domstatic-vs-glasgow}
%% tmp %% %%     \caption{mcsplit-si-vs-glasgow}
%% tmp %% %%     \label{figure:mcsplit-si-vs-glasgow}
%% tmp %% %% \end{figure}
%% tmp %% %% 
%% tmp %% %% \begin{figure}[h!]
%% tmp %% %%     \centering
%% tmp %% %%     \includegraphics*[width=0.45\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/mcsplit-si-vs-vf3}
%% tmp %% %%     \caption{mcsplit-si-vs-vf3}
%% tmp %% %%     \label{figure:mcsplit-si-vs-vf3}
%% tmp %% %% \end{figure}
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \subsection{Knight's grid instances}\label{subsec:si-knights-experiment}
%% tmp %% 
%% tmp %% Our second set of decision-problem instances were proposed by Knuth in a recent pre-fascicle
%% tmp %% of The Art of Computer Programming \cite{knuth2022art}.  Each pattern graph is a rectangular grid
%% tmp %% $P_m \square P_n$, and each target graph is a knight graph $N_t$ which has one vertex for each
%% tmp %% square of a $t \times t$ chessboard and an edge between any two squares that are a knight's
%% tmp %% move (two squares horizontally and one square vertically or vice versa) apart.
%% tmp %% \Cref{figure:knights-example} shows the pattern and target graph for one such instance,
%% tmp %% with a solution shown on the target graph.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][The grid $P_2 \square P_{24}$] {
%% tmp %%         \centering
%% tmp %%         \includegraphics*[width=0.36\textwidth]{14b-mcsplit-induced-si/knight-grid-experiment/img/p2-p24.pdf}
%% tmp %%         \label{figure:grid-p2-p24}
%% tmp %%     }
%% tmp %%     \subfigure[][The knight graph $N_{12}$] {
%% tmp %%         \centering
%% tmp %%         \includegraphics*[width=0.36\textwidth]{14b-mcsplit-induced-si/knight-grid-experiment/img/12-by-12-p2-p24.pdf}
%% tmp %%         \label{figure:knight12}
%% tmp %%     }
%% tmp %%     \caption{A satisfiable knight's grid instance. On the left is the pattern graph; on the right
%% tmp %%             is the target graph with an induced subgraph isomorphic to the pattern shown by heavy
%% tmp %%             nodes and edges.}\label{figure:knights-example}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% If $m=1$ and $n=t^2$, we have the classic knight's tour problem in which a single knight
%% tmp %% must visit every square of the chessboard without revisiting any square.  The instances proposed
%% tmp %% by Knuth have $m \in \{2,3,4\}$.
%% tmp %% Clearly, the embedding of each row and of each column of the grid graph must itself be a miniature
%% tmp %% knight's tour.
%% tmp %% Thus, these instances may be interpreted as the problem of moving $m$
%% tmp %% knights --- themselves organised in the formation of a knight's tour of length $m$ ---
%% tmp %% around the board without changing their positions relative to each other, and without revisiting
%% tmp %% any square.  In the induced case (which is the only case we consider here), there
%% tmp %% is the additional restriction that no knight attacks any square except the square that it has
%% tmp %% just visited, the square it will visit next, and the squares of its neighbours in the miniature
%% tmp %% tour of length $m$.
%% tmp %% 
%% tmp %% \paragraph{Instances}
%% tmp %% 
%% tmp %% For $m \in \{2,3,4\}$, we considered instances of the form ``is $P_m \square P_n$ isomorphic
%% tmp %% to a subgraph of $K_k$, with $k \geq 4$ and $n$ equal to either the largest value for which
%% tmp %% the instance is satisfiable or the smallest value for which the instance is unsatisfiable.
%% tmp %% 
%% tmp %% The vertices of each graph were randomly permuted to ensure that the vertex
%% tmp %% order does not give clues to the solvers that might make the satisfiable
%% tmp %% instances artificially easy.  The same pair of permuted graphs was given to
%% tmp %% each solver.
%% tmp %% 
%% tmp %% \paragraph{Results for satisfiable instances}
%% tmp %% Tables \ref{tab:KnightSat2} to \ref{tab:KnightSat4} show run times for satisfiable instances.
%% tmp %% \McSplit-SI-static, Glasgow without supplemental graphs, and RI are excluded from the tables for brevity,
%% tmp %% because they are outperformed by \McSplit-SI, Glasgow, and RI respectively.
%% tmp %% \McSplit-SI and \McSplit-SI-LL both outperformed \McSplit-SI-AM, as we would expect given the
%% tmp %% sparsity of the instances.
%% tmp %% For instances with pattern graphs of the form $P_2 \square P_n$,
%% tmp %% there was no clear winning solver, but RI-DS and VF3 performed very well overall.
%% tmp %% For instances with pattern graphs of the form $P_3 \square P_n$, there was again no clear winner.
%% tmp %% \McSplit-SI-LL was the best solver overall for instances with pattern graphs of the form $P_4 \square P_n$,
%% tmp %% running orders of magnitude faster than all of the non-\McSplit-SI solvers on many instances.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/knight-grid-experiment/experiment/fatanode-results/knight-sat-2}
%% tmp %% \caption{Runtimes in ms for satisfiable knight's grid instances with pattern graphs of
%% tmp %%         the form $P_2 \square P_n$.  An asterisk indicates timeout at $10\,000$ seconds;
%% tmp %%         the best run time for each instance is underlined.  Trivial instances that all solvers
%% tmp %%         could solve in less than 10 ms are not shown.}
%% tmp %% \label{tab:KnightSat2}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/knight-grid-experiment/experiment/fatanode-results/knight-sat-3}
%% tmp %% \caption{Runtimes in ms for satisfiable knight's grid instances with pattern graphs of
%% tmp %%         the form $P_3 \square P_n$.}
%% tmp %% \label{tab:KnightSat3}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/knight-grid-experiment/experiment/fatanode-results/knight-sat-4}
%% tmp %% \caption{Runtimes in ms for satisfiable knight's grid instances with pattern graphs of
%% tmp %%         the form $P_4 \square P_n$.}
%% tmp %% \label{tab:KnightSat4}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \paragraph{Results for unsatisfiable instances}
%% tmp %% Tables \ref{tab:KnightSat2} to \ref{tab:KnightSat4} show run times for unsatisfiable instances.
%% tmp %% For each of these families of instances, \McSplit-SI-LL is the overall winner. Among the
%% tmp %% non-\McSplit\ solvers, Glasgow is the fastest constraint programming solver and RI-DS
%% tmp %% is the fastest other solver.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/knight-grid-experiment/experiment/fatanode-results/knight-unsat-2}
%% tmp %% \caption{Runtimes in ms for unsatisfiable knight's grid instances with pattern graphs of
%% tmp %%         the form $P_2 \square P_n$.}
%% tmp %% \label{tab:KnightUnsat2}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/knight-grid-experiment/experiment/fatanode-results/knight-unsat-3}
%% tmp %% \caption{Runtimes in ms for unsatisfiable knight's grid instances with pattern graphs of
%% tmp %%         the form $P_3 \square P_n$.}
%% tmp %% \label{tab:KnightUnsat3}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%     \input{14b-mcsplit-induced-si/knight-grid-experiment/experiment/fatanode-results/knight-unsat-4}
%% tmp %% \caption{Runtimes in ms for unsatisfiable knight's grid instances with pattern graphs of
%% tmp %%         the form $P_3 \square P_n$.}
%% tmp %% \label{tab:KnightUnsat4}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \paragraph{Knuth's specialised program}
%% tmp %% The goal of this experiment was to compare a set of general-purpose subgraph isomorphism
%% tmp %% solvers on an interesting set of benchmark instances, but we should note that the solvers
%% tmp %% compared here are far from the fastest way to solve the specific problem of embedding
%% tmp %% a large grid in an knight graph.
%% tmp %% Donald Knuth, in preparing \citet{knuth2022art}, wrote a series of six specialised
%% tmp %% programs for finding such maximal embeddings.  To give an example of the programs' run times,
%% tmp %% the program \texttt{back-knightgrid2-strict} takes less than
%% tmp %% three seconds to find the largest $k$ such that $P_2 \square P_k$
%% tmp %% is isomorphic to an induced subgraph of $K_{14}$; the fastest
%% tmp %% program in our experiment needs more than 600 seconds to solve the same problem.
%% tmp %% Among several other interesting techniques, Knuth's programs use symmetry breaking;
%% tmp %% it would certainly be possible to add symmetry breaking to each of the solvers considered
%% tmp %% here in order to decrease their run times on these instances \citep{zampelli2007symmetry}.
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \subsection{Enumeration instances}\label{subsec:si-enumeration-experiment}
%% tmp %% 
%% tmp %% Our final set of benchmark instances is based on the MIVIA LDGraphs dataset
%% tmp %% \citep{DBLP:journals/pami/CarlettiFSV18}.  In each LDGraphs instance, the pattern and
%% tmp %% target graphs are random directed graphs without edge labels.
%% tmp %% Some of the instances have vertex labels.
%% tmp %% Although the results of benchmarking graph algorithms on such instances cannot
%% tmp %% always be extrapolated to real-world instances \citep{DBLP:conf/cp/McCreeshPST17},
%% tmp %% we include these instances because they are the an established benchmark set,
%% tmp %% and in particular they are the main set of instances used by \cite{DBLP:journals/pami/CarlettiFSV18}
%% tmp %% to demonstrate the performance of VF3.
%% tmp %% 
%% tmp %% Rather than using the instance files provided by the authors of the MIVIA LDGraphs
%% tmp %% dataset, we chose to generate our own random graphs from the same model and with the
%% tmp %% same parameters.  We made this choice for two reasons: first, because of the large size
%% tmp %% of the LDGraphs files (90 GBytes compressed), and second, so that we could augment
%% tmp %% the set of instances with sparser pairs of graphs.
%% tmp %% 
%% tmp %% In each instance, both the pattern and target graph are generated using a directed-graph
%% tmp %% version of the Erd\H{o}s-Rényi $G(n,p)$ model.  In this model, a graph on $n$ vertices
%% tmp %% is generated, and each of the $n(n-1)$ possible directed edges is added with independent
%% tmp %% probability $p$.  Carletti et al.\ use the values $\{0.2, 0.3, 0.4\}$ for $p$. In our experiment
%% tmp %% we additionally use the values $0.05$ and $0.1$.
%% tmp %% 
%% tmp %% Following Carletti et al., we generate two families of directed graphs: an unlabelled family
%% tmp %% and a family with no edge labels in which the vertex labels are chosen uniformly at random
%% tmp %% from the set $\{1,\dots,8\}$.  (Carletti et al.\ generated a third family, in which labels
%% tmp %% are chosen from a non-uniform distribution.  Their experimental results show very similar
%% tmp %% outcomes for the uniform and non-uniform families, and therefore we have omitted the non-uniform
%% tmp %% family from our experiment.)
%% tmp %% 
%% tmp %% For each value of $p$, we use the values
%% tmp %% of $n$ for the target graph that were used by Carletti et al.; these are shown in \Cref{tab:carletti-n}.
%% tmp %% In each instance, a randomly-selected subset of $20\%$ of the target vertices is selected,
%% tmp %% and the subgraph induced by this subset is used as the pattern graph.  Thus, each instance
%% tmp %% is satisfiable (and a typical instance has exactly one solution).
%% tmp %% 
%% tmp %% We do not include the LAD solver in our experiments because
%% tmp %% the experimental results of \cite{DBLP:journals/pami/CarlettiFSV18} show that LAD
%% tmp %% is orders of magnitude slower than VF3 on instances constructed in
%% tmp %% this way.
%% tmp %% 
%% tmp %% \begin{table}[htb]
%% tmp %% \centering
%% tmp %% \footnotesize
%% tmp %%  \begin{tabular}{p{0.2\linewidth} p{0.35\linewidth} p{0.35\linewidth}}
%% tmp %%  \toprule
%% tmp %%      $p$ & Target graph $n$ (unlabelled) & Target graph $n$ (labelled) \\ [0.5ex]
%% tmp %%  \midrule
%% tmp %%      $0.05$, $0.01$, and $0.2$ &
%% tmp %%          300, 500, 750, 1000, 1250, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000 &
%% tmp %%          300, 500, 750, 1000, 1250, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000,
%% tmp %%          5500, 6000, 6500, 7000, 7500, 8000, 9000, 10000\\
%% tmp %%      \rule{0pt}{2.3ex}$0.3$ & 
%% tmp %%         300, 500, 750, 1000, 1250, 1500, 2000, 2500, 3000 &
%% tmp %%         300, 500, 750, 1000, 1250, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000,
%% tmp %%         5500, 6000, 6500, 7000, 7500, 8000, 9000 \\
%% tmp %%      \rule{0pt}{2.3ex}$0.4$ & 300, 500, 750, 1000, 1250, 1500 &
%% tmp %%         300, 500, 750, 1000, 1250, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000 \\
%% tmp %%  \bottomrule
%% tmp %% \end{tabular}
%% tmp %% \caption{Values of $n$ used in enumeration instances}
%% tmp %% \label{tab:carletti-n}
%% tmp %% \end{table}
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \paragraph*{Results for unlabelled instances}
%% tmp %% 
%% tmp %% \Cref{figure:unlabelled-vf-instance-runtimes} shows run times for the unlabelled instances.
%% tmp %% Since the instances have a natural ordering by the parameter $n$, we follow the example
%% tmp %% of \cite{DBLP:journals/pami/CarlettiFSV18} and plot average run time as a function of $n$
%% tmp %% rather than using cumulative plots.
%% tmp %% Each point shows, for a given solver and given values of $n$ and $p$, the arithmetic mean of
%% tmp %% run time in milliseconds for the 10 instances.
%% tmp %% The time limit was set to 10000 seconds because many of the larger instances in this experiment
%% tmp %% are particularly challenging.  Runs that exceeded the time limit were counted as taking 10000 seconds;
%% tmp %% since none of the \McSplit-SI runs timed out, this does not affect the \McSplit-SI results but biases
%% tmp %% the results slightly in favour of the other algorithms.  In cases where all ten runs timed out,
%% tmp %% the data point is omitted from the plot (as, for example,  is the case for RI with $p=0.4$ and $n=7000$).
%% tmp %% 
%% tmp %% For all five values of $p$, either \McSplit-SI or \McSplit-SI-AM is the fastest algorithm.  For
%% tmp %% the smallest two values of $p$, \McSplit-SI is the winner; for $p=0.2$ and above, \McSplit-SI-AM
%% tmp %% is slightly faster.  This is as we would expect, since \McSplit-SI is designed to work well
%% tmp %% on instances with sparse pattern and target graphs.  
%% tmp %% \McSplit-SI-LL typically takes around two to three times as long as \McSplit-SI to find all solutions.
%% tmp %% 
%% tmp %% For each value of $p$, there is approximately an order of magnitude difference in run time between
%% tmp %% the fastest variant of \McSplit-SI and the fastest non-\McSplit-SI algorithm.
%% tmp %% On sparser instances, VF3 and RI-DS have the closest run times to \McSplit-SI.  Around $p=0.1$,
%% tmp %% the Glasgow solver with supplemental graphs disabled becomes competitive with these algorithm, and at $p=0.4$
%% tmp %% it is at least an order of magnitude faster than either VF3 or RI-DS.
%% tmp %% 
%% tmp %% When using the Glasgow solver, it is worthwhile to disable supplemental graphs
%% tmp %% on all but 11 of the instances.  In fact, supplemental graphs have no effect on
%% tmp %% the size of the search tree on the majority of instances, since most pairs of
%% tmp %% vertices in this set of instances are joined by many paths of length 2; thus,
%% tmp %% on this set of instances supplemental graphs have a double overhead --- in
%% tmp %% their construction and in their use during search --- with no corresponding
%% tmp %% benefit.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][Key] {
%% tmp %%         \includegraphics*[trim=-40 -30 -40 -30,width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/key.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.05$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.05-1.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.1$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.1-1.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.2$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.2-1.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.3$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.3-1.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.4$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.4-1.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \caption{Run times on unlabelled enumeration instances with random directed pattern and target graphs}
%% tmp %%     \label{figure:unlabelled-vf-instance-runtimes}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \FloatBarrier
%% tmp %% 
%% tmp %% \paragraph*{Results for vertex-labelled instances}
%% tmp %% 
%% tmp %% \Cref{figure:unlabelled-vf-instance-runtimes} shows run times for instances with labelled vertices.
%% tmp %% As was the case for the unlabelled instances, \McSplit-SI is the fastest solver for sparse instances and \McSplit-SI-AM
%% tmp %% is the fastest solver for dense instances (with the exception of the smallest dense instances,
%% tmp %% where \McSplit-SI is fastest).  VF3 is the fastest non-CP solver for every value of $p$, and indeed is almost
%% tmp %% as fast as \McSplit-SI for $p=0.05$.  Around $p=0.3$, the Glasgow solver
%% tmp %% with supplemental graphs disabled overtakes VF3 as the fastest non-\McSplit-SI solver.
%% tmp %% 
%% tmp %% The difference between Glasgow with and without supplemental graphs is even larger on these labelled instances
%% tmp %% than on the labelled instances, exceeding one order of magnitude in many cases.
%% tmp %% 
%% tmp %% \begin{figure}[htb]
%% tmp %%     \centering
%% tmp %%     \subfigure[][Key] {
%% tmp %%         \includegraphics*[trim=-40 -30 -40 -30,width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/key.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.05$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.05-8.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.1$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.1-8.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.2$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.2-8.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.3$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.3-8.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \subfigure[][$p=0.4$] {
%% tmp %%         \includegraphics*[width=0.44\textwidth]{14b-mcsplit-induced-si/vf3-instances-experiment/experiment/plots/runtimes0.4-8.pdf}
%% tmp %%         \label{figure:TODO}
%% tmp %%     }
%% tmp %%     \caption{Run times on unlabelled enumeration instances with random directed pattern and target graphs}
%% tmp %%     \label{figure:labelled-vf-instance-runtimes}
%% tmp %% \end{figure}
%% tmp %% 
%% tmp %% \FloatBarrier

\section{Using the \McSplit-SI data structures for MCIS}

We have so far seen dense and sparse variants of \McSplit\ for induced subgraph isomorphism, and
a dense variant for maximum common induced subgraph.  The algorithm that is missing from this
list---a sparse variant for MCIS---can be straightforwardly created by modifying \McSplit-SI. 
We will call this new algorithm \McSplit-sparse.

An implementation of \McSplit-sparse
requires only a few small changes to the code of \McSplit-SI. We
therefore give a brief account of the required changes rather than a full
description of the algorithm.  The \McSplit-sparse algorithm uses the same
sequence-of-decision-problems strategy as \McSplitDown. Thus the call to
\FuncSty{Search} on \lineref{McSplitSIFirstExpandCall} of \Cref{McSplitSIAlg}
is replaced by a sequence of calls, one for each goal order of the common
subgraph.  The \FuncSty{Search} function takes an extra parameter: the current
upper bound. The \FuncSty{Filter} function updates this bound each time a label
class is partitioned, and returns early if the bound falls below the goal.

\subsection{Experimental evaluation of \McSplit-sparse}

Following the lead of \cite{DBLP:conf/cpaior/ArchibaldDHMP019},
we use the 14,621 subgraph isomorphism instances described
\Cref{subsec:si-decision-experiment} as our benchmark set.
This provides a challenging set of instances; in particular,
many of the Meshes and Images instances that can be solved in less
than a second by \McSplit-SI are very difficult for all of the maximum
common subgraph solvers.

To summarise the results of \cite{DBLP:conf/cpaior/ArchibaldDHMP019}
for these instances, 

TODO say that Ciaran has shown that kdown outperforms McSplit.

\Cref{figure:mcsplit-sparse-scatter-by-family}

\begin{figure}[htb]
    \centering
    \caption{TODO}
    \includegraphics*[width=0.92\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/cumulative.pdf}
    \label{figure:mcsplit-sparse-cumulative}
\end{figure}

\begin{figure}[htb]
    \centering
    \subfigure[][Scalefree] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-Scalefree.pdf}
        \label{figure:TODO}
    }
    \subfigure[][LV] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-LV.pdf}
        \label{figure:TODO}
    }
    \subfigure[][BVG] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-BVG.pdf}
        \label{figure:TODO}
    }

    \subfigure[][M4D] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-M4D.pdf}
        \label{figure:TODO}
    }
    \subfigure[][Rand] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-Rand.pdf}
        \label{figure:TODO}
    }
    \subfigure[][PR] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-PR.pdf}
        \label{figure:TODO}
    }

    \subfigure[][Phase] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-Phase.pdf}
        \label{figure:TODO}
    }
    \subfigure[][Meshes] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-Meshes.pdf}
        \label{figure:TODO}
    }
    \subfigure[][Images] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/by-family/scatter-Images.pdf}
        \label{figure:TODO}
    }
    \caption{Run times in ms of \McSplit-sparse (horizontal axis) and k$\downarrow$+restarts (vertical axis), by family.}
    \label{figure:mcsplit-sparse-scatter-by-family}
\end{figure}

\McSplit-sparse solves 242 more Images instances and 92 more LV instances
within the 1000 second time limit than $k\downarrow$+restarts. On the other
hand, $k\downarrow$+restarts solves more instances than \McSplit-sparse in the
BVG, M4D, Meshes and Rand families: a total of 56 more instances across these
four families.

\begin{figure}[htb]
    \centering
    \caption{TODO (rescaled)}
    \includegraphics*[width=0.92\textwidth]{14b-mcsplit-induced-si/sip-instances-mcis-experiment/experiment/plots/cumulative-rescaled.pdf}
    \label{figure:mcsplit-sparse-cumulative-rescaled}
\end{figure}

\section{Verification}

For each of the decision instances, we verified that all of the programs that did not time out
agreed on whether the instance was satistfiable or unsatisfiable.  For enumeration instances,
we verified that the solvers agreed on the number of solutions.

In addition, we checked the number of search nodes visited by \McSplit-SI,
\McSplit-SI-LL, and \McSplit-SI-AM
on instances where neither solver timed out.  In each case, the counts of search nodes were equal,
indicating that --- as expected --- the three solvers explored exactly the same search tree.

I verified that the the pseudocode in this chapter accurately describes the \McSplit-SI
algorithm by re-implementing the algorithm in Python from the pseudocode and checking
that it gives the same result and search node count as the original C++ implementation.

I used my own generator to produce the grid and knight graphs.  To verify the
correctness of the generated graphs, I used the built-in graph generators of
SageMath \citep{sagemath} to generate grid and knight graphs with the same
parameters, and used SageMath again to ensure that my graphs were isomorphic to
the graphs generated by that program.

\section{Conclusion}

We have introduced a version of \McSplit\ for the induced subgraph isomorphism problem that is time- and memory-efficient for large, sparse graphs.
We have shown experimentally that this algorithm outperforms state-of-the-art algorithms on many instances.
Compared to the pattern-recognition solvers RI and VF3, \McSplit-SI appears to be a clear improvement
on the instances considered, with the exception of some satisfiable knights' grid instances.  The situation
with respect to the Glasgow Subgraph Solver is more complex, yet \McSplit-SI clearly outperforms Glasgow on
two of the three experiments, and is a strong competitor even on the hard decision instances
where Glasgow performs best.

As a minor contribution of this chapter, our experimental evaluation has
brought to light two potential improvements to the Glasgow solver.  First, the
algorithm could swap the degree-based heuristic (or alternatively, work on
complement graphs) if the density of the target graph exceeds $0.5$.  Second,
the algorithm should discard supplemental graphs that can be determined in
advance to provide no domain filtering.

Future work could use the data structures of McSplit-SI in the McSplit algorithm for maximum common induced subgraph.
TODO future work could include portfolio with algorithm selection by target graph density.
TODO maybe save future work for final chapter

\section{Recycle Bin}

\begin{figure}[htb]
    \centering
    \subfigure[][Glasgow] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-presolve-mcsplit-glasgow}
        \label{figure:TODO}
    }
    \subfigure[][Glasgow, no supp.] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-presolve-mcsplit-glasgow-nosupp}
        \label{figure:TODO}
    }
    \subfigure[][RI] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-presolve-mcsplit-ri}
        \label{figure:TODO}
    }
    \subfigure[][RI-DS] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-presolve-mcsplit-ri-ds}
        \label{figure:TODO}
    }
    \subfigure[][VF3] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-presolve-mcsplit-vf3}
        \label{figure:TODO}
    }
    \subfigure[][\McSplit-SI-LL] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-presolve-mcsplit-si-ll}
        \label{figure:TODO}
    }
    \subfigure[][\McSplit-SI-AM] {
        \includegraphics*[width=0.22\textwidth]{14b-mcsplit-induced-si/decision-instances-experiment/experiment/plots/scatter-presolve-mcsplit-si-am}
        \label{figure:TODO}
    }
    \caption{Scatter plots of run times in ms for decision instances.
            The horizontal axis shows the the run time of \McSplit-SI-static
            with a 100 ms \McSplit-SI presolve; the vertical axis shows
            the run time of the solver named in the subfigure caption.}
    \label{figure:TODO}
\end{figure}

