\algnewcommand{\IfNDebug}[1]{#1}
%\algnewcommand{\IfNDebug}[1]{}

\chapter{Swapping the graphs in \McSplit}
\label{c:swapping-graphs-mcsplit}

\section{Introduction}

Given graphs $G$ and $H$, it is clear that a maximum common subgraph of $H$ and $G$ is
also a maximum common subgraph of $G$ and $H$.  In this chapter, we ask whether
it is ever useful to swap the two input graphs when calling a maximum common subgraph
solver.  We will see that swapping the graphs can have a very large effect on the
execution time of \McSplit\
if the two graphs differ in density or order.  Finally, we introduce a modified
version of \McSplit\ that generalises the idea of swapping graphs.

\section{When should we swap the graphs?}

We begin by plotting run times of \McSplit\ with and without swapping graphs, to
give an idea of the difference that swapping can make.  We refer to the swapping
version of \McSplit\ as \McSplit-Swap; this is shown in
\Cref{McSplitSwapAlg}.

\begin{algorithm}[h!]
\DontPrintSemicolon
\nl $\FuncSty{McSplit-Swap}(G, H)$ \label{McSplitSwapFun} \;
\nl \Begin{
    \nl $M \gets \FuncSty{McSplit}(H,G)$ \LeftComment{Call \McSplit\ with the graphs swapped}\;
    \nl $\KwSty{return}$~$\{(w, v) \mid (v, w) \in M\}$ \LeftComment{Reverse the mapping}
}
    \caption{\McSplit-Swap: a version of \McSplit\ that swaps the input graphs.} 
\label{McSplitSwapAlg}
\end{algorithm}

\Cref{subfig:runtime-swapping-scatter-mcsplain}
shows run times for the MCS Plain instances.  The horizontal axis shows run time
without swapping the graphs; the vertical axis shows run time with swapping.  Although swapping
graphs can make a small difference, it does not change run time by as much as an order of 
magnitude for any of these instances.

\begin{figure}[h!]
    \centering
    \subfigure[][MCS Plain instances] {
        \centering
        \includegraphics*[width=0.44\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/left-vs-right-mcsplain}
        \label{subfig:runtime-swapping-scatter-mcsplain}
    }
    \subfigure[][Random 24-vertex instances] {
        \centering
        \includegraphics*[width=0.44\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/left-vs-right-random2}
        \label{subfig:runtime-swapping-scatter-random2}
    }
    \caption{Run times in ms for \McSplit\ (horizontal axis) and \McSplit\ with graphs $G$ and $H$ swapped
        (vertical axis).  Each point represents one graph pair.  Swapping the graphs has little effect on run time
        for MCS Plain instances, but changes the run time by orders of magnitude
        for many of the random instances.}\label{figure:runtime-swapping-scatter}
\end{figure}

Within each MCS Plain instance, the two graphs are very similar: they are produced
using the same graph generator, have the same number of vertices, and have very similar density.
(See \Cref{figure:mcsplain-densities} in the appendix for a scatter plot of densities.)
Thus, it is unsurprising that swapping the graphs has little effect on run time.
To examine pairs of graphs with very different characteristics, we generated two
sets of random instances using the Erdos-Renyi $G(n,p)$ model.  The first set has
24 vertices per graph, with the $p$ parameter of the generator chosen randomly from
$\{0.01, 0.02, \dots, 0.99\}$; thus, the graphs have the same order but vary
greatly in density.  The second set of instances has the density parameter
$p$ set to $0.3$ for all instances, with the number of vertices in each graph randomly
chosen from $\{10, 11, \dots, 40\}$.

\Cref{subfig:runtime-swapping-scatter-random2} shows run times with and without swapping
for the first set of random graphs.  For these instances, unlike the MCS Plain instances,
there are very clearly some instances for which swapping graphs is beneficial, and others
for which swapping greatly increases the run time.

\subsection{Random graphs with fixed $n$ and varying density}

Can we tell in advance whether we should swap the graphs of a given instance?
\Cref{figure:coloured-scatter-run-times-density} shows that, in the case of our
random 24-vertex instances, there is a very strong association between the densities
of the two graphs and whether we should swap graphs.  In this plot, the axes
measure graph density,\footnote{By \emph{density}, we are referring to the actual density of a graph,
$\frac{|E(G)|}{n_G(n_G-1)/2}$, rather than the parameter $p$ used to generate
the graph. In practice the two measures are very similar.}. Colour is used to show
the effect of swapping graphs on run time; red dots represent those instances
that are solved more quickly with the graphs swapped.  The diagonal lines on the plot
are $y=x$ and $y=1-x$; these divide the plot into four triangular regions.
The figure shows clearly that instances lying
in the upper and lower triangles tend to be solved more quickly by \McSplit, while
those lying in the left and right triangles tend to be solved more
quickly by \McSplit-Swap.

\begin{figure}[h!]
    \centering
    \subfigure[][Density] {
        \centering
        \includegraphics*[width=0.44\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/density-when-swap}
        \label{figure:coloured-scatter-run-times-density}
    }
    \subfigure[][``Extremeness'' of density] {
        \centering
        \includegraphics*[width=0.44\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/density-extremeness-when-swap}
        \label{figure:coloured-scatter-run-times-extremeness}
    }
    \caption{There is a strong association between the densities of graphs $G$ and $H$
        and whether it is beneficial to use \McSplit-Swap rather than \McSplit.
        The first subfigure plots density of $G$ against density of $H$, with one point
        plotted for each of the random 24-vertex instances.  Instances for which \McSplit-Swap
        is faster are plotted in red; instances where \McSplit\ is faster
        are plotted in blue.  Dark red and dark blue indicate that \McSplit-Swap and \McSplit,
        respectively, result in run times at least twice as fast as the alternative.}
        \label{figure:coloured-scatter-mcis-run-times}
\end{figure}

The union of the left and right triangles in
\Cref{figure:coloured-scatter-run-times-density} has a simple characterisation.
Define the measure \emph{density extremeness} of
a graph as $\left|\frac{1}{2} - d\right|$, where $d$ is the graph's
density.  This is simply a measure of how close a graph's
density is to either 0 or 1; thus, a clique and an independent set
have the highest possible density extremeness.  The union of the left and right triangles
in \Cref{figure:coloured-scatter-run-times-density} contains exactly those
graph pairs $(G,H)$ such that the density extremeness of $G$ is greater than
the density extremeness of $H$.
The second subfigure, \Cref{figure:coloured-scatter-run-times-extremeness},
replots the data in \Cref{figure:coloured-scatter-run-times-density},
with density extremeness rather than density measured on the axes.
It is evident from the figure that for instances such that the density extremeness of $G$
exceeds the density extremeness of $H$, \McSplit-Swap almost always
runs faster than \McSplit.

Given the strong relationship between the densities of $G$ and $H$ and the 
optimal order in which to pass the graphs to \McSplit, a natural next
step is to devise a version of \McSplit\ such that the graphs are
swapped if and only if the density extremeness of $G$ is greater
than the density extremeness of $H$.  We call this algorithm
\McSplit-SD; it is shown in \Cref{McSplitSDAlg}.

\begin{algorithm}[h!]
\DontPrintSemicolon
\nl $\FuncSty{McSplit-SD}(G, H)$ \label{McSplitSDFun} \;
\nl \Begin{
    \nl \If{$\left|\frac{1}{2} - d_G\right| > \left|\frac{1}{2} - d_H\right|$}{
        \nl $\KwSty{return}$~$\FuncSty{McSplit-Swap}(G,H)$ \;
    }
    \nl $\KwSty{return}$~$\FuncSty{McSplit}(G,H)$
}
    \caption{\McSplit-SD: a version of \McSplit\ that uses density to decide whether to swap the input graphs.} 
\label{McSplitSDAlg}
\end{algorithm}

\Cref{figure:left-vs-smart-d-mcis} compares on our set of 24-vertex random instances
the run times of three solvers: \McSplit, \McSplit-SD, and the virtual best solver (VBS) of
\McSplit\ and \McSplit-Swap.  The cumulative plot shows that \McSplit-Swap and the VBS
have almost identical performance overall, and that both outperform \McSplit.  The scatter
plot in \Cref{figure:left-vs-smart-random2} shows that \McSplit-SD is never much slower than
\McSplit\ on these instances, and is orders of magnitude faster on several of the
instances.  In summary, for this family of instances, \McSplit-SD clearly improves upon
\McSplit, and makes near-perfect decisions when selecting between \McSplit\ and \McSplit-Swap.

\begin{figure}[h!]
    \centering
    \subfigure[][Cumulative plot of instances solved] {
        \centering
        \includegraphics*[width=0.52\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/mcsplit-random-smart-density-cumulative}
        \label{figure:left-vs-smart-density-cumulative}
    }
    \subfigure[][Run times (ms)] {
        \centering
        \includegraphics*[width=0.41\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/left-vs-smart-random2}
        \label{figure:left-vs-smart-random2}
    }
    \caption{The run times of \McSplit-SD are faster overall than those of \McSplit\ for the
        random 24-vertex instances, and almost indistinguishable from those of the virtual
        best solver of \McSplit\ and \McSplit\ with swapped graphs.}
        \label{figure:left-vs-smart-d-mcis}
\end{figure}

\subsection{Random graphs with similar density and varying $n$}

We now turn to our family of random instances generated with $p=0.3$ and varying values of
the order parameter $n$.  \Cref{figure:order-when-swap} shows a strong relationship between
the graphs' densities and the relative run times of \McSplit\ and \McSplit-Swap: \McSplit\
is generally preferable if $G$ has fewer vertices than $H$, and \McSplit-Swap is preferable
if $G$ has more vertices than $H$.

\begin{figure}[h!]
    \centering
    \includegraphics*[width=0.5\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/order-when-swap}
    \caption{For our random $p=0.3$ instances, is is preferable to use \McSplit\ when $G$
        has fewer vertices than $H$, and to use \McSplit-Swap when $G$ has more vertices than $H$.
        The plot shows one point per instance.  Instances for which \McSplit-Swap
        is faster are plotted in red; instances where \McSplit\ is faster
        are plotted in blue.  Dark red and dark blue indicate that \McSplit-Swap and \McSplit,
        respectively, result in run times at least twice as fast as the alternative.}
    \label{figure:order-when-swap}
\end{figure}

\McSplit-SO, an algorithm that swaps the graphs if the order of $G$ is greater than the
order of $H$, is shown in \Cref{McSplitSOAlg}.
\Cref{figure:left-vs-smart-o-mcis} shows the run times of \McSplit, \McSplit-SO,
and the VBS of \McSplit\ and \McSplit-Swap for our $p=0.3$ instances.  As in our earlier
experiment with \McSplit-SD, the \McSplit-SO algorithm performs about as well as the
VBS, and is not substantially slower than \McSplit\ on any instance.  However, the improvement
provided by \McSplit-SO is less dramatic than that provided by \McSplit-SD; \McSplit-SO
is seldom more than an order of magnitude faster than \McSplit\ on non-trivial instances.

\begin{algorithm}[h!]
\DontPrintSemicolon
\nl $\FuncSty{McSplit-SO}(G, H)$ \label{McSplitSOFun} \;
\nl \Begin{
    \nl \If{$n_G > n_H$}{
        \nl $\KwSty{return}$~$\FuncSty{McSplit-Swap}(G,H)$ \;
    }
    \nl $\KwSty{return}$~$\FuncSty{McSplit}(G,H)$
}
    \caption{\McSplit-SO: a version of \McSplit\ that uses vertex counts to decide whether to swap the input graphs.} 
\label{McSplitSOAlg}
\end{algorithm}

\begin{figure}[h!]
    \centering
    \subfigure[][Cumulative plot of instances solved] {
        \centering
        \includegraphics*[width=0.52\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/mcsplit-random-smart-order-cumulative}
        \label{figure:left-vs-smart-order-cumulative}
    }
    \subfigure[][Run times (ms)] {
        \centering
        \includegraphics*[width=0.41\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/left-vs-smart-random3}
        \label{figure:left-vs-smart-random3}
    }
    \caption{The run times of \McSplit-SD are faster overall than those of \McSplit\ for the
        random 24-vertex instances, and almost indistinguishable from those of the virtual
        best solver of \McSplit\ and \McSplit\ with swapped graphs.}
        \label{figure:left-vs-smart-o-mcis}
\end{figure}

\section{Explaining the success of \McSplit-SD and \McSplit-SO}

Why are \McSplit-SD and \McSplit-SO effective?  In this section, we give reasons related
to the bound calculated at each search node that go some way towards explaining
the success of the swapping heuristics.  In each case, we start with an example,
then broaden the discussion to the general case.  The arguments presented in this
section are qualitative, and there is certainly scope in future work for more precise
arguments for the effectiveness of the two algorithm variants.

We begin by considering \McSplit-SO; that is, we
ask why it is useful to select the graph with fewer vertices as the first argument
when calling \McSplit.  Let $G$
be a graph with $n_G$ vertices and $H$ be a graph with $n_H$ vertices, such that $n_G < n_H$.
If we call $\McSplit(G,H)$, the first call to $\FuncSty{Search()}$ in \Cref{McSplitAlg}
makes $n_H + 1$ recursive calls to $\FuncSty{Search()}$: one for each vertex $w \in V(H)$,
and a final call to reject vertex $v$ of $G$.  Thus, the root node of the search tree
has $n_H + 1$ children. If we reverse the order of the graphs and
call $\McSplit(H,G)$, a similar argument shows that the root node of the search tree
has $n_G + 1$ children.  Thus --- at least at the root node and plausibly also deeper in the
tree --- the search tree has a smaller branching factor if we call \McSplit\ with the
\emph{larger} graph first.

If we were to follow the standard constraint programming practice of branching
on the smallest domain first \cite{DBLP:journals/ai/HaralickE80}, we would 
therefore call $\McSplit(H,G)$ --- that is, we would place the larger graph first.
But this is exactly the opposite of the \McSplit-SO strategy.
Therefore, we must look elsewhere to explain why calling \McSplit\ with the small
graph first is effective.  It seems likely that the bound calculated on \lineref{CalcBound}
of \Cref{McSplitAlg} is part of the explanation.

To give a concrete example, consider the example graphs $G$ and $H$ from
\Cref{fig:alg1}, which are reproduced for convenience in \Cref{figure:G-and-H-redux}.
\Cref{figure:search-tree-without-swapping} shows the search tree if --- following the
strategy of \McSplit-SO --- the smaller graph is passed first to \McSplit.
\Cref{figure:search-tree-with-swapping} shows the search tree if the larger graph
is passed first to \McSplit.  These search trees have 35 and 45 nodes respectively;
as we might expect, passing the smaller graph first results in a smaller search tree.

\begin{figure}[htb]
    \centering
    \subfigure[][$G$ and $H$] {
        \centering
            \scalebox{0.8}{
                \tikz {
                    \begin{scope}[yshift=2.8cm]
                        \graph [nodes={draw, circle, minimum width=.55cm, inner sep=1pt}, circular placement, radius=0.95cm,
                                clockwise=5] {
                                    1,2,3,4,5;
                            1--4; 1--5; 2--3; 2--5; 3--5;
                        };
                    \end{scope}
                    \graph [nodes={draw, circle, minimum width=.55cm, inner sep=1pt}, circular placement, radius=0.95cm,
                            clockwise=6, phase=60] {
                                a,b,c,d,e,f;
                        a--b; a--c; a--e; b--d; b--f; c--d; c--e; c--f; d--f; e--f;
                    };
                    \node at (0,-.5) {};  % for positioning
                }
            }
        \label{figure:G-and-H-redux}
    }
    \subfigure[][The search tree of $\McSplit(G,H)$] {
        \centering
        \scalebox{0.85}{
            \IfNDebug{\input{14a-mcsplit-swapping/branching-example/james-cpp-modified/treegh-b-and-b-highlighted.tex}}
        }
        \label{figure:search-tree-without-swapping}
    }
    \subfigure[][The search tree of $\McSplit(H,G)$] {
        \centering
        \scalebox{0.85}{
            \IfNDebug{\input{14a-mcsplit-swapping/branching-example/james-cpp-modified/treehg-b-and-b-highlighted.tex}}
        }
        \label{figure:search-tree-with-swapping}
    }
    \caption{The search trees of \McSplit\ and \McSplit-Swap on example graphs $G$ and $H$.  Each blue box
            highlights the search tree explored after making the decision not to map a vertex in the first
            call to $\FuncSty{Search}()$.}
        \label{figure:search-trees-with-swapping}
\end{figure}

The blue rectangle on each search tree highlights the subproblem after the final branching
decision in the first call to $\FuncSty{Search}()$ --- the decision not to use the first
vertex in the first graph (vertex $1$ in \Cref{figure:search-tree-without-swapping}
and vertex $a$ in \Cref{figure:search-tree-with-swapping}).  The size difference between
these highlighted subtrees --- 1 vertex and 16 vertices --- is more than enough to account
for the overall difference in size between the two search trees.  The subtree in
\Cref{figure:search-tree-without-swapping} is small because after rejecting a vertex of
the smaller graph, we can reduce the bound to 4 which lets us prune the search tree immediately.
In \Cref{figure:search-tree-without-swapping}, the rejected vertex belongs to the larger
side of the label class, and therefore the bound remains at 5.

Clearly, this argument generalises: for any two graphs of unequal order,
the final child of the search tree's root node will have a smaller bound
if we call \McSplit\ with the smaller graph first than if we call the algorithm
with the larger graph first.  This provides at least some explanation for the success of
\McSplit-SO.

We now turn to \McSplit-SD.  Why might passing the graph with the lowest density
extremeness first to \McSplit\ result in a smaller search tree.  As an example, we
use graph $G$ from the previous example along with edgeless graph on five vertices
$I_5$.  These graphs have density extremeness $0$ and $0.5$ respectively --- the
minimum and maximum possible values.  Thus, using the heuristic of \McSplit-SD,
we would expect the search tree of $\McSplit(G, I_5)$ to be smaller than the search
tree of $\McSplit(I_5, G)$.  Indeed, this is the case; the search trees,
which are shown in \Cref{figure:search-trees-gi-with-swapping}, have 44
and 97 nodes respectively.

\begin{figure}[htb]
    \centering
    \subfigure[][$G$ and $I_5$] {
        \centering
            \scalebox{0.67}{
                \tikz {
                    \begin{scope}[yshift=2.5cm]
                        \graph [nodes={draw, circle, minimum width=.55cm, inner sep=1pt}, circular placement, radius=0.95cm,
                                clockwise=5] {
                                    1,2,3,4,5;
                            1--4; 1--5; 2--3; 2--5; 3--5;
                        };
                    \end{scope}
                    \graph [nodes={draw, circle, minimum width=.55cm, inner sep=1pt}, circular placement, radius=0.8cm,
                            clockwise=5] {
                                a,b,c,d,e;
                    };
                    %% \node at (0,-.5) {};  % for positioning
                }
            }
        \label{figure:G-and-I5}
    }
    \subfigure[][The search tree of $\McSplit(G,I_5)$] {
        \centering
        \scalebox{0.73}{
            \IfNDebug{\input{14a-mcsplit-swapping/branching-example/james-cpp-modified/treegi-b-and-b.tex}}
        }
        \label{figure:search-tree-gi-without-swapping}
    }
    \subfigure[][The search tree of $\McSplit(I_5,G)$] {
        \centering
        \scalebox{0.73}{
            \IfNDebug{\input{14a-mcsplit-swapping/branching-example/james-cpp-modified/treeig-b-and-b.tex}}
        }
        \label{figure:search-tree-gi-with-swapping}
    }
    \caption{The search trees of \McSplit\ and \McSplit-Swap on example graphs $G$ and $I_5$.}
        \label{figure:search-trees-gi-with-swapping}
\end{figure}

Why might it be preferable to call \McSplit\ with $I_5$ as the second
rather than the first graph?  We argue
that the reason is similar to the reason we gave for placing the smaller graph
first in our previous discussion.  It is clear that when calling \McSplit\ with
$G$ and $I_5$ (in either order), there will be exactly one label class throughout
search, consisting of the vertices in both graphs that have not been explicitly
rejected by the algorithm and that are not adjacent to any vertex that has already
been mapped.  The side of that label class containing vertices of $G$ will tend to
contain fewer vertices than the side containing vertices of $I_5$, since the vertex set of $I_5$ is
an independent set.  
Now consider a red branch in either search tree, in which a vertex is rejected.
If that vertex is on the smaller side of the label class, the bound at the child node
in the search tree will be one less than the bound at the parent node; otherwise,
the bound at the child node will be equal to the bound at the parent node.  It is
therefore preferable, in our example, to call \McSplit\ with $G$ first.  Indeed,
in \Cref{figure:search-trees-gi-with-swapping} we can see that there are ten
nodes in the search tree of $\McSplit(I_5, G)$ that result from the rejection of
a vertex (i.e. have a red-labelled edge above) and have the same bound as their
parent.  There are no such nodes in the search tree of $\McSplit(I_5, G)$.

The average branching factor of the search tree for $\McSplit(I_5, G)$ is lower
than the average branching factor of the search tree for $\McSplit(G, I_5)$.  This
suggests than with \McSplit-SD, as is the case for \McSplit-SO, there is a trade-off
where the average branching factor suggests we should use one ordering of the
graphs, but this is outweighed by the better bounds computed with the opposite
ordering.

\section{Generalising \McSplit-SD and \McSplit-SO}

Our arguments in favour of \McSplit-SD and \McSplit-SO both point towards the benefit
of choosing a vertex in the smaller side of a label class to branch on in the
$\FuncSty{Search}()$ function of \McSplit.  This suggests a modified version of \McSplit\ in
which branching may be carried out on vertices of either graph, with the decision of
which side to choose based on the relative sizes of the sides of label class.  We
show this algorithm, \McSplit2, in \Cref{McSplit2Alg}.

Compared to \Cref{McSplitAlg}, the changed section of code is on
\linerangeref{ChooseBranchingSideMS2}{LastNewLineMS2}.  (In addition,
the function $\FuncSty{NewFuture}$, which creates the new label classes
after a vertex assignment, has been extracted to avoid duplication.)
\Lineref{ChooseBranchingSideMS2} chooses which side to branch on.
If the side of label class $\langle \setG, \setH\rangle$ containing
vertices from the first graph is no larger than the other side of the label class,
the algorithm maps a vertex from $\setG$ to each vertex
in $\setH$ in turn (\linerangeref{RemoveVMS2}{EndOfBranch1MS2}), just
as in the standard \McSplit\ algorithm.  Otherwise, the algorithm
maps a vertex from $\setH$ to each vertex in $\setG$ in turn
(\linerangeref{RemovewMS2Swap}{LastNewLineMS2}).

\begin{algorithm}[h!]
\DontPrintSemicolon
\nl $\FuncSty{NewFuture}(\AlgVar{future},v,w)$ \;
\nl \Begin{
\nl    $\AlgVar{future'} \gets \emptyset$ \label{NewFutureMS2} \;
\nl    \For {$\langle \setG',\setH'\rangle \in future$ \label{InnerLoopMS2}}{
\nl        $\setG'' \gets \setG' \cap \N(\graphG, v) \setminus \{v\}$ \label{NewPWithEdgeMS2} \;
\nl        $\setH'' \gets \setH' \cap \N(\graphH, w) \setminus \{w\}$ \;
\nl        \If {$\setG'' \neq \emptyset$ \bf{and} $\setH'' \neq \emptyset$\label{IfNonEmptyMS2}}{
\nl            $\AlgVar{future'} \gets \AlgVar{future'} \cup \{\langle \setG'' , \setH'' \rangle\}$ \label{AddToFutureWithEdgeMS2}}
\nl        $\setG'' \gets \setG' \cap \invN(\graphG, v) \setminus \{v\}$ \label{NewPWithoutEdgeMS2}  \;
\nl        $\setH'' \gets \setH' \cap \invN(\graphH, w) \setminus \{w\}$ \;
\nl        \If {$\setG'' \neq \emptyset$ \bf{and} $\setH'' \neq \emptyset$\label{IfNonEmpty2MS2}}{
\nl            $\AlgVar{future'} \gets \AlgVar{future'} \cup \{\langle \setG'' , \setH'' \rangle\}$} \label{InnerLoopEndMS2}
       }
\nl $\KwSty{return}$~$\AlgVar{future'}$ \;
}
\medskip
\nl $\FuncSty{Search}(\AlgVar{future},M)$ \;
\nl \Begin{
%\nl \lIf {$\AlgVar{future} = \emptyset$ \bf{and} $|M| > |\AlgVar{incumbent}|$}
\nl \lIf {$|M| > |\AlgVar{incumbent}|$}{$\AlgVar{incumbent} \gets M$} \label{StoreIncumbentMS2}
%\nl \lIf {$\AlgVar{future} = \emptyset$}{return}
\medskip
\nl $\AlgVar{bound} \gets |M|  + \sum_{\langle \setG,\setH \rangle \in \AlgVar{future}} \min(|\setG|,|\setH|)$ \label{CalcBoundMS2} \;
\nl \lIf {$\AlgVar{bound} \leq |\AlgVar{incumbent}|$}{\KwSty{return}} \label{PruneSearchMS2}
\medskip
\nl $\langle \setG,\setH \rangle \gets \FuncSty{SelectLabelClass}(\AlgVar{future})$ \label{SelectClassMS2} \;
\nl \If{$|\setG| \leq |\setH|$ \label{ChooseBranchingSideMS2}} {
\nl   \LeftComment{Branch as in standard \McSplit} \;
\nl   $v \gets \FuncSty{SelectVertex}(\setG)$ \label{SelectVertexMS2} \;
\nl   \For {$w \in \setH$ \label{WLoopMS2}} {
\nl     $\FuncSty{Search}(\FuncSty{NewFuture}(\AlgVar{future}, v, w),M\cup \{(v,w)\})$ \label{ExpandWithVMS2} \;
  }
\nl   $\setG' \gets \setG \setminus \{v\}$ \label{RemoveVMS2} \;
\nl   $\AlgVar{future} \gets \AlgVar{future} \setminus \{\langle \setG,\setH \rangle\}$\;
\nl   \lIf {$\setG' \neq \emptyset$ \label{EndOfBranch1MS2}} {$\AlgVar{future} \gets \AlgVar{future} \cup \{\langle \setG',\setH \rangle \}$}
      } \nl \Else {
\nl   \LeftComment{Swapped version: branch on a vertex of $H$} \;
\nl   $w \gets \FuncSty{SelectVertex}(\setH)$ \label{SelectVertexMS2Swap} \;
\nl   \For {$v \in \setG$ \label{vLoopMS2Swap}} {
\nl     $\FuncSty{Search}(\FuncSty{NewFuture}(\AlgVar{future}, v, w),M\cup \{(v,w)\})$ \label{ExpandWithwMS2Swap} \;
  }
\nl   $\setH' \gets \setH \setminus \{w\}$ \label{RemovewMS2Swap} \;
\nl   $\AlgVar{future} \gets \AlgVar{future} \setminus \{\langle \setG,\setH \rangle\}$\;
\nl   \lIf {$\setH' \neq \emptyset$ \label{LastNewLineMS2}} {$\AlgVar{future} \gets \AlgVar{future} \cup \{\langle \setG,\setH' \rangle \}$}
    }
\nl $\FuncSty{Search}(\AlgVar{future},M)$ \label{ExpandWithoutVMS2} \;
}
\;
\nl $\FuncSty{McSplit2}(\graphG,\graphH)$ \label{McSplitFunMS2} \;
\nl \Begin{
    \nl $\KwSty{global}~\AlgVar{incumbent} \gets \emptyset$ \;
\nl $\FuncSty{Search}(\{\langle V(\graphG),V(\graphH) \rangle \},\emptyset)$ \label{FirstExpandCallMS2} \;
\nl $\KwSty{return}$~$\AlgVar{incumbent}$ \;
}
\caption{McSplit2: a branch-and-bound algorithm to find a maximum common induced subgraph of two graphs.}
\label{McSplit2Alg}
\end{algorithm}

\begin{figure}[h!]
    \centering
    \subfigure[][TODO] {
        \centering
        \includegraphics*[width=0.46\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/random2-mcsplit2-cumulative}
        \label{figure:TODO1}
    }
    \subfigure[][TODO] {
        \centering
        \includegraphics*[width=0.46\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/random3-mcsplit2-cumulative}
        \label{figure:TODO2}
    }
    \subfigure[][TODO] {
        \centering
        \includegraphics*[width=0.46\textwidth]{14-mcsplit-i-undirected/modified-mcsplit-experiment/plots/plots/mcsplain-mcsplit2-cumulative}
        \label{figure:TODO3}
    }
    \caption{TODO}
    \label{figure:TODO4}
\end{figure}

TODO: pseudocode for mcsplit-F

Do cumumlative curves
for two random families and mcsplain with mcsplit-f, mcsplit-F, mcsplit.  Show that mcsplit-F helps a bit for random families
and doesn't require knowledge of either order nor density.  Give negative result for mcsplain: mcsplit-F doesn't seem to help
much, but scatter shows that mcsplit-f is a little bit bad.

\section{Things to write about}

\begin{itemize}
    \item McSplit-F
    \item K and H algorithm - show that swapping is useful
    \item Same for Versari algorithm?
\end{itemize}
